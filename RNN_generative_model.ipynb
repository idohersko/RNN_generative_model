{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "from gensim.models import Word2Vec\n",
    "#from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.utils import plot_model \n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import pretty_midi\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from plot_keras_history import show_history, plot_history\n",
    "import seaborn as sns\n",
    "import math \n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras import backend as K\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lyrics_set(path):\n",
    "    columns = [\"artist\", \"song_1\", \"lyrics_1\", \"song_2\", \"lyrics_2\", \"song_3\", \"lyrics_3\"]\n",
    "    df = pd.read_csv(path, names=columns, header=None)\n",
    "    \n",
    "    # Create an empty DataFrame with the desired columns\n",
    "    new_df = pd.DataFrame(columns=['artist', 'song', 'lyrics', 'midi_file'])\n",
    "\n",
    "    # Iterate over the original DataFrame row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the values from the current row\n",
    "        artist = row['artist']\n",
    "        song_1 = row['song_1']\n",
    "        lyrics_1 = row['lyrics_1']\n",
    "        \n",
    "        # Add the current row to the new DataFrame\n",
    "        new_df = pd.concat([new_df, pd.DataFrame({'artist': [artist], 'song': [song_1], 'lyrics': [lyrics_1]})], ignore_index=True)\n",
    "        \n",
    "        # Check if song_name_3 is not NaN\n",
    "        if not pd.isnull(row['song_2']):\n",
    "            # Extract the values from the next two rows\n",
    "            song_2 = row['song_2']\n",
    "            lyrics_2 = row['lyrics_2']\n",
    "            new_df = pd.concat([new_df, pd.DataFrame({'artist': [artist], 'song': [song_2], 'lyrics': [lyrics_2]})], ignore_index=True)\n",
    "            \n",
    "            if not pd.isnull(row['song_3']):\n",
    "                song_3 = row['song_3']\n",
    "                lyrics_3 = row['lyrics_3']\n",
    "                new_df = pd.concat([new_df, pd.DataFrame({'artist': [artist], 'song': [song_3], 'lyrics': [lyrics_3]})], ignore_index=True)\n",
    "    \n",
    "    new_df['song'] = new_df['song'].str.strip()\n",
    "    new_df['artist'] = new_df['artist'].str.strip()\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midi_file_name_to_df(df, folder_path):\n",
    "    # Iterate over the MIDI files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mid\"):\n",
    "            # Extract the artist and song names from the file name\n",
    "            artist = filename.split(\"_-_\")[0].lower().replace(\"_\", \" \")\n",
    "            song = filename.split(\"_-_\")[1].lower().replace(\"_\", \" \").replace(\".mid\", \"\")\n",
    "            # Find the matching row in the DataFrame by artist and song\n",
    "            match_row = df[(df['artist'].str.lower() == artist) & (df['song'].str.lower() == song)]\n",
    "            # Check if a match is found\n",
    "            if not match_row.empty:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    try:\n",
    "                        # Attempt to load the MIDI file\n",
    "                        pretty_midi.PrettyMIDI(f\"{folder_path}/{filename}\")\n",
    "\n",
    "                        # Get the index of the match row\n",
    "                        match_index = match_row.index[0]\n",
    "\n",
    "                        # Update the \"midi_file\" column with the original MIDI file name\n",
    "                        df.at[match_index, 'midi_file'] = filename\n",
    "                    except:\n",
    "                        print(f\"Error processing MIDI file: {filename}\")\n",
    "\n",
    "    # Remove rows with NaN or None values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Reset the index after removing rows\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text):\n",
    "    replacements = {\n",
    "    r\"\\bisn't\\b\": \"is not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\baren't\\b\": \"are not\",\n",
    "    r\"\\bwasn't\\b\": \"was not\",\n",
    "    r\"\\bweren't\\b\": \"were not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bcan't\\b\": \"cannot\",\n",
    "    r\"\\bcouldn't\\b\": \"could not\",\n",
    "    r\"\\bshouldn't\\b\": \"should not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bmightn't\\b\": \"might not\",\n",
    "    r\"\\bmustn't\\b\": \"must not\",\n",
    "    r\"\\bI'm\\b\": \"I am\",\n",
    "    r\"\\byou're\\b\": \"you are\",\n",
    "    r\"\\bhe's\\b\": \"he is\",\n",
    "    r\"\\bshe's\\b\": \"she is\",\n",
    "    r\"\\bit's\\b\": \"it is\",\n",
    "    r\"\\bwe're\\b\": \"we are\",\n",
    "    r\"\\bthey're\\b\": \"they are\",\n",
    "    r\"\\bi've\\b\": \"I have\",\n",
    "    r\"\\byou've\\b\": \"you have\",\n",
    "    r\"\\bwe've\\b\": \"we have\",\n",
    "    r\"\\bthey've\\b\": \"they have\",\n",
    "    r\"\\bi'd\\b\": \"I would\",\n",
    "    r\"\\byou'd\\b\": \"you would\",\n",
    "    r\"\\bhe'd\\b\": \"he would\",\n",
    "    r\"\\bshe'd\\b\": \"she would\",\n",
    "    r\"\\bit'd\\b\": \"it would\",\n",
    "    r\"\\bwe'd\\b\": \"we would\",\n",
    "    r\"\\bthey'd\\b\": \"they would\",\n",
    "    r\"\\bi'll\\b\": \"I will\",\n",
    "    r\"\\byou'll\\b\": \"you will\",\n",
    "    r\"\\bhe'll\\b\": \"he will\",\n",
    "    r\"\\bshe'll\\b\": \"she will\",\n",
    "    r\"\\bit'll\\b\": \"it will\",\n",
    "    r\"\\bwe'll\\b\": \"we will\",\n",
    "    r\"\\bthey'll\\b\": \"they will\",\n",
    "}\n",
    "\n",
    "    # Apply the replacements\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    # Split the text into individual words\n",
    "    words = text.split()\n",
    "\n",
    "    # Filter out the '&' symbol\n",
    "    words = [word for word in words if word != \"&\"]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(words):\n",
    "    \"\"\"\n",
    "    Cleans a list of words by removing any non-alphabetic characters from each word.\n",
    "\n",
    "    Args:\n",
    "        words (list): A list of words to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of cleaned words.\n",
    "    \"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        cleaned_word = re.sub(r'[^a-zA-Z]', '', word)\n",
    "        cleaned_words.append(cleaned_word)\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lyrics_tokens(df):\n",
    "    \"\"\"\n",
    "    Creates a new DataFrame column with tokenized lyrics by processing the existing lyrics column.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing columns 'artist', 'song', 'lyrics', 'midi_file'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with an additional column 'lyrics_tokens' containing tokenized lyrics.\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    df2 = pd.DataFrame(columns=['artist', 'song', 'lyrics', 'midi_file', 'lyrics_tokens'])\n",
    "\n",
    "    new_df = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "    for index, row in new_df.iterrows():\n",
    "        tokens = replace_words(row['lyrics'].lower())\n",
    "        tokens = clean_words(tokens)\n",
    "        new_df.at[index, 'lyrics_tokens'] = tokens\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, test, validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing MIDI file: Aaron_Neville_-_Tell_It_Like_It_Is.mid\n",
      "Error processing MIDI file: Beastie_Boys_-_Girls.mid\n",
      "Error processing MIDI file: Billy_Joel_-_Movin'_Out.mid\n",
      "Error processing MIDI file: Billy_Joel_-_Pressure.mid\n",
      "Error processing MIDI file: Brian_McKnight_-_On_The_Down_Low.mid\n",
      "Error processing MIDI file: Dan_Fogelberg_-_Leader_of_the_Band.mid\n",
      "Error processing MIDI file: David_Bowie_-_Lazarus.mid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>midi_file</th>\n",
       "      <th>lyrics_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elton john</td>\n",
       "      <td>candle in the wind</td>\n",
       "      <td>goodbye norma jean &amp; though i never knew you a...</td>\n",
       "      <td>Elton_John_-_Candle_in_the_Wind.mid</td>\n",
       "      <td>[goodbye, norma, jean, though, i, never, knew,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gerry rafferty</td>\n",
       "      <td>baker street</td>\n",
       "      <td>winding your way down on baker street &amp; lite i...</td>\n",
       "      <td>Gerry_Rafferty_-_Baker_Street.mid</td>\n",
       "      <td>[winding, your, way, down, on, baker, street, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gerry rafferty</td>\n",
       "      <td>right down the line</td>\n",
       "      <td>you know i need your love &amp; you've got that ho...</td>\n",
       "      <td>Gerry_Rafferty_-_Right_Down_the_Line.mid</td>\n",
       "      <td>[you, know, i, need, your, love, you, have, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 unlimited</td>\n",
       "      <td>tribal dance</td>\n",
       "      <td>come on check it out ya'll &amp; (come on come on!...</td>\n",
       "      <td>2_Unlimited_-_Tribal_Dance.mid</td>\n",
       "      <td>[come, on, check, it, out, yall, come, on, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 unlimited</td>\n",
       "      <td>let the beat control your body</td>\n",
       "      <td>let the beat control your body &amp; let the beat ...</td>\n",
       "      <td>2_Unlimited_-_Let_the_Beat_Control_Your_Body.mid</td>\n",
       "      <td>[let, the, beat, control, your, body, let, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>don henley</td>\n",
       "      <td>dirty laundry</td>\n",
       "      <td>i make my living off the evening news &amp; just g...</td>\n",
       "      <td>Don_Henley_-_Dirty_Laundry.mid</td>\n",
       "      <td>[i, make, my, living, off, the, evening, news,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>don henley</td>\n",
       "      <td>new york minute</td>\n",
       "      <td>harry got up &amp; dressed all in black &amp; went dow...</td>\n",
       "      <td>Don_Henley_-_New_York_Minute.mid</td>\n",
       "      <td>[harry, got, up, dressed, all, in, black, went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>bob dylan</td>\n",
       "      <td>subterranean homesick blues</td>\n",
       "      <td>johnny's in the basement &amp; mixing up the medic...</td>\n",
       "      <td>Bob_Dylan_-_Subterranean_Homesick_Blues.mid</td>\n",
       "      <td>[johnnys, in, the, basement, mixing, up, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>goldfinger</td>\n",
       "      <td>mable</td>\n",
       "      <td>i met her sunday that was yesterday &amp; the girl...</td>\n",
       "      <td>Goldfinger_-_Mable.mid</td>\n",
       "      <td>[i, met, her, sunday, that, was, yesterday, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>dr dre</td>\n",
       "      <td>forgot about dre</td>\n",
       "      <td>y'all know me still the same o.g. but i been l...</td>\n",
       "      <td>Dr_Dre_-_Forgot_About_Dre.mid</td>\n",
       "      <td>[yall, know, me, still, the, same, og, but, i,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                            song  \\\n",
       "0        elton john              candle in the wind   \n",
       "1    gerry rafferty                    baker street   \n",
       "2    gerry rafferty             right down the line   \n",
       "3       2 unlimited                    tribal dance   \n",
       "4       2 unlimited  let the beat control your body   \n",
       "..              ...                             ...   \n",
       "597      don henley                   dirty laundry   \n",
       "598      don henley                 new york minute   \n",
       "599       bob dylan     subterranean homesick blues   \n",
       "600      goldfinger                           mable   \n",
       "601          dr dre                forgot about dre   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    goodbye norma jean & though i never knew you a...   \n",
       "1    winding your way down on baker street & lite i...   \n",
       "2    you know i need your love & you've got that ho...   \n",
       "3    come on check it out ya'll & (come on come on!...   \n",
       "4    let the beat control your body & let the beat ...   \n",
       "..                                                 ...   \n",
       "597  i make my living off the evening news & just g...   \n",
       "598  harry got up & dressed all in black & went dow...   \n",
       "599  johnny's in the basement & mixing up the medic...   \n",
       "600  i met her sunday that was yesterday & the girl...   \n",
       "601  y'all know me still the same o.g. but i been l...   \n",
       "\n",
       "                                            midi_file  \\\n",
       "0                 Elton_John_-_Candle_in_the_Wind.mid   \n",
       "1                   Gerry_Rafferty_-_Baker_Street.mid   \n",
       "2            Gerry_Rafferty_-_Right_Down_the_Line.mid   \n",
       "3                      2_Unlimited_-_Tribal_Dance.mid   \n",
       "4    2_Unlimited_-_Let_the_Beat_Control_Your_Body.mid   \n",
       "..                                                ...   \n",
       "597                    Don_Henley_-_Dirty_Laundry.mid   \n",
       "598                  Don_Henley_-_New_York_Minute.mid   \n",
       "599       Bob_Dylan_-_Subterranean_Homesick_Blues.mid   \n",
       "600                            Goldfinger_-_Mable.mid   \n",
       "601                     Dr_Dre_-_Forgot_About_Dre.mid   \n",
       "\n",
       "                                         lyrics_tokens  \n",
       "0    [goodbye, norma, jean, though, i, never, knew,...  \n",
       "1    [winding, your, way, down, on, baker, street, ...  \n",
       "2    [you, know, i, need, your, love, you, have, go...  \n",
       "3    [come, on, check, it, out, yall, come, on, com...  \n",
       "4    [let, the, beat, control, your, body, let, the...  \n",
       "..                                                 ...  \n",
       "597  [i, make, my, living, off, the, evening, news,...  \n",
       "598  [harry, got, up, dressed, all, in, black, went...  \n",
       "599  [johnnys, in, the, basement, mixing, up, the, ...  \n",
       "600  [i, met, her, sunday, that, was, yesterday, th...  \n",
       "601  [yall, know, me, still, the, same, og, but, i,...  \n",
       "\n",
       "[602 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'lyrics_train_set.csv'\n",
    "folder_path = r'midi_files'\n",
    "train_df = read_lyrics_set(path)\n",
    "train_df = add_midi_file_name_to_df(train_df, folder_path)\n",
    "train_df = create_lyrics_tokens(train_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>midi_file</th>\n",
       "      <th>lyrics_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the bangles</td>\n",
       "      <td>eternal flame</td>\n",
       "      <td>close your eyes give me your hand darling &amp; d...</td>\n",
       "      <td>The_Bangles_-_Eternal_Flame.mid</td>\n",
       "      <td>[close, your, eyes, give, me, your, hand, darl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search for tenderness &amp; it isn't hard ...</td>\n",
       "      <td>Billy_Joel_-_Honesty.mid</td>\n",
       "      <td>[if, you, search, for, tenderness, it, is, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardigans</td>\n",
       "      <td>lovefool</td>\n",
       "      <td>dear i fear we're facing a problem &amp; you love...</td>\n",
       "      <td>Cardigans_-_Lovefool.mid</td>\n",
       "      <td>[dear, i, fear, we, are, facing, a, problem, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aqua</td>\n",
       "      <td>barbie girl</td>\n",
       "      <td>hiya barbie &amp; hi ken! &amp; do you want to go for...</td>\n",
       "      <td>Aqua_-_Barbie_Girl.mid</td>\n",
       "      <td>[hiya, barbie, hi, ken, do, you, want, to, go,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blink 182</td>\n",
       "      <td>all the small things</td>\n",
       "      <td>all the small things &amp; true care truth brings...</td>\n",
       "      <td>Blink_182_-_All_the_Small_Things.mid</td>\n",
       "      <td>[all, the, small, things, true, care, truth, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                  song  \\\n",
       "0  the bangles         eternal flame   \n",
       "1   billy joel               honesty   \n",
       "2    cardigans              lovefool   \n",
       "3         aqua           barbie girl   \n",
       "4    blink 182  all the small things   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0   close your eyes give me your hand darling & d...   \n",
       "1   if you search for tenderness & it isn't hard ...   \n",
       "2   dear i fear we're facing a problem & you love...   \n",
       "3   hiya barbie & hi ken! & do you want to go for...   \n",
       "4   all the small things & true care truth brings...   \n",
       "\n",
       "                              midi_file  \\\n",
       "0       The_Bangles_-_Eternal_Flame.mid   \n",
       "1              Billy_Joel_-_Honesty.mid   \n",
       "2              Cardigans_-_Lovefool.mid   \n",
       "3                Aqua_-_Barbie_Girl.mid   \n",
       "4  Blink_182_-_All_the_Small_Things.mid   \n",
       "\n",
       "                                       lyrics_tokens  \n",
       "0  [close, your, eyes, give, me, your, hand, darl...  \n",
       "1  [if, you, search, for, tenderness, it, is, not...  \n",
       "2  [dear, i, fear, we, are, facing, a, problem, y...  \n",
       "3  [hiya, barbie, hi, ken, do, you, want, to, go,...  \n",
       "4  [all, the, small, things, true, care, truth, b...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'lyrics_test_set.csv'\n",
    "folder_path = r'midi_files'\n",
    "test_df = read_lyrics_set(path)\n",
    "test_df = add_midi_file_name_to_df(test_df, folder_path)\n",
    "test_df = create_lyrics_tokens(test_df)\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(train_df, test_size=0.05, random_state=42)\n",
    "train_df.reset_index(inplace=True)\n",
    "validation_df.reset_index(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "\n",
    "# Create a list of all the words in the lyrics\n",
    "list_of_lists_for_word2vec = []\n",
    "for i in list(train_df['lyrics_tokens']):\n",
    "    list_of_lists_for_word2vec.append(i)\n",
    "for i in list(validation_df['lyrics_tokens']):\n",
    "    list_of_lists_for_word2vec.append(i)\n",
    "for i in list(test_df['lyrics_tokens']):\n",
    "    list_of_lists_for_word2vec.append(i)\n",
    "    \n",
    "w2v_model = Word2Vec(list_of_lists_for_word2vec, min_count=1, vector_size=300, window=5)\n",
    "\n",
    "all_words_in_corpus = w2v_model.wv.index_to_key\n",
    "all_words_in_corpus_dict = w2v_model.wv.key_to_index\n",
    "all_words_in_corpus_inverted_dict = {value: key for key, value in all_words_in_corpus_dict.items()}\n",
    "all_words_in_corpus_size = len(all_words_in_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_column(tokenized_lyrics_data):\n",
    "    \"\"\" \n",
    "    Retrieves word embeddings for each token in the tokenized lyrics data.\n",
    "\n",
    "    Args:\n",
    "        tokenized_lyrics_data (list): A list of tokenized lyrics data.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of word embeddings for each token in the tokenized lyrics data.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = []\n",
    "    for lyrics in tokenized_lyrics_data:\n",
    "        lyric_embeddings = []\n",
    "        for word in lyrics:\n",
    "            lyric_embeddings.append(w2v_model.wv[word])\n",
    "        embeddings.append(np.array(lyric_embeddings))\n",
    "    return np.array(embeddings, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['word2vec_embeddings'] = get_embeddings_column(list(train_df['lyrics_tokens']))\n",
    "validation_df['word2vec_embeddings'] = get_embeddings_column(list(validation_df['lyrics_tokens']))\n",
    "test_df['word2vec_embeddings'] = get_embeddings_column(list(test_df['lyrics_tokens']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Extraction of Midi Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_midi_features(df):\n",
    "    piano_max = float('-inf')\n",
    "    piano_min = float('inf')\n",
    "\n",
    "    total_velocity_max = float('-inf')\n",
    "    total_velocity_min = float('inf')\n",
    "\n",
    "    \n",
    "    tempo_max = float('-inf')\n",
    "    tempo_min = float('inf')\n",
    "\n",
    "\n",
    "    tempo_changes_max = float('-inf')\n",
    "    tempo_changes_min = float('inf')\n",
    "\n",
    "\n",
    "    ints_total_notes_max = float('-inf')\n",
    "    ints_total_notes_min = float('inf')\n",
    "\n",
    "\n",
    "    ints_total_pitch_bends_max = float('-inf')\n",
    "    ints_total_pitch_bends_min = float('inf')\n",
    "\n",
    "\n",
    "    ints_total_control_changes_max = float('-inf')\n",
    "    ints_total_control_changes_min = float('inf')\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        mid = pretty_midi.PrettyMIDI(folder_path + \"/\" + row['midi_file'])\n",
    "        total_velocity = sum(sum(mid.get_chroma()))\n",
    "        tempo = mid.estimate_tempo()\n",
    "        tempo_changes = mid.get_tempo_changes()[0].shape[0]\n",
    "        piano = np.mean(mid.get_piano_roll(fs=1).flatten())\n",
    "        \n",
    "\n",
    "        #piano_roll_value_normalized = (np.mean(mid.get_piano_roll(fs=1).flatten()) - min_pianoRoll) / (max_pianoRoll - min_pianoRoll)\n",
    "        ints_total_notes = 0\n",
    "        ints_total_pitch_bends = 0\n",
    "        ints_total_control_changes = 0\n",
    "        for instrument in mid.instruments:\n",
    "            if not instrument.is_drum:\n",
    "                ints_total_notes += len(instrument.notes)\n",
    "                ints_total_pitch_bends += len(instrument.pitch_bends)\n",
    "                ints_total_control_changes += len(instrument.control_changes)\n",
    "\n",
    "        # Update max_x and min_x\n",
    "        if piano > piano_max:\n",
    "            piano_max = piano\n",
    "        if piano < piano_min:\n",
    "            piano_min = piano\n",
    "\n",
    "        \n",
    "        # Update max_x and min_x\n",
    "        if total_velocity > total_velocity_max:\n",
    "            total_velocity_max = total_velocity\n",
    "        if total_velocity < total_velocity_min:\n",
    "            total_velocity_min = total_velocity\n",
    "\n",
    "                # Update max_x and min_x\n",
    "        if tempo > tempo_max:\n",
    "            tempo_max = tempo\n",
    "        if tempo < tempo_min:\n",
    "            tempo_min = tempo\n",
    "\n",
    "                # Update max_x and min_x\n",
    "        if tempo_changes > tempo_changes_max:\n",
    "            tempo_changes_max = tempo_changes\n",
    "        if tempo_changes < tempo_changes_min:\n",
    "            tempo_changes_min = tempo_changes\n",
    "\n",
    "                # Update max_x and min_x\n",
    "        if ints_total_notes > ints_total_notes_max:\n",
    "            ints_total_notes_max = ints_total_notes\n",
    "        if ints_total_notes < ints_total_notes_min:\n",
    "            ints_total_notes_min = ints_total_notes\n",
    "        \n",
    "                # Update max_x and min_x\n",
    "        if ints_total_pitch_bends > ints_total_pitch_bends_max:\n",
    "            ints_total_pitch_bends_max = ints_total_pitch_bends\n",
    "        if ints_total_pitch_bends < ints_total_pitch_bends_min:\n",
    "            ints_total_pitch_bends_min = ints_total_pitch_bends\n",
    "\n",
    "                # Update max_x and min_x\n",
    "        if ints_total_control_changes > ints_total_control_changes_max:\n",
    "            ints_total_control_changes_max = ints_total_control_changes\n",
    "        if ints_total_control_changes < ints_total_control_changes_min:\n",
    "            ints_total_control_changes_min = ints_total_control_changes\n",
    "        \n",
    "    return piano_max, piano_min, total_velocity_max, total_velocity_min, tempo_max, tempo_min, tempo_changes_max, tempo_changes_min, ints_total_notes_max, ints_total_notes_min, ints_total_pitch_bends_max, ints_total_pitch_bends_min, ints_total_control_changes_max, ints_total_control_changes_min\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_insert_into_df_general_midi_features(df):\n",
    "    \"\"\"\n",
    "    Extracts general MIDI features from MIDI files and inserts them into the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing the 'midi_file' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The modified DataFrame with additional columns for the extracted MIDI features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a new column 'midi_file_features_global' in the DataFrame with an empty array for each row\n",
    "    df['midi_file_features_global'] = pd.Series([np.array([])] * len(df))\n",
    "\n",
    "    # Retrieve the minimum and maximum values of MIDI features from the DataFrame\n",
    "    piano_max, piano_min, total_velocity_max, total_velocity_min, tempo_max, tempo_min, tempo_changes_max, tempo_changes_min, ints_total_notes_max, ints_total_notes_min, ints_total_pitch_bends_max, ints_total_pitch_bends_min, ints_total_control_changes_max, ints_total_control_changes_min = get_min_max_midi_features(df)\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        # Load the MIDI file using the `pretty_midi.PrettyMIDI` class\n",
    "        mid = pretty_midi.PrettyMIDI(folder_path + \"/\" + row['midi_file'])\n",
    "\n",
    "        try:\n",
    "            # Calculate and normalize various MIDI features\n",
    "            total_velocity = (sum(sum(mid.get_chroma())) - total_velocity_min) / (total_velocity_max - total_velocity_min)\n",
    "            tempo = (mid.estimate_tempo() - tempo_min) / (tempo_max - tempo_min)\n",
    "            tempo_changes = (mid.get_tempo_changes()[0].shape[0] - tempo_changes_min) / (tempo_changes_max - tempo_changes_min)\n",
    "            piano_roll_value = (np.mean(mid.get_piano_roll(fs=1).flatten()) - piano_min) / (piano_max - piano_min)\n",
    "\n",
    "            # Calculate the count of various MIDI events\n",
    "            ints_total_notes = 0\n",
    "            ints_total_pitch_bends = 0\n",
    "            ints_total_control_changes = 0\n",
    "            for instrument in mid.instruments:\n",
    "                if not instrument.is_drum:\n",
    "                    ints_total_notes += len(instrument.notes)\n",
    "                    ints_total_pitch_bends += len(instrument.pitch_bends)\n",
    "                    ints_total_control_changes += len(instrument.control_changes)\n",
    "\n",
    "            # Normalize the count of MIDI events\n",
    "            ints_total_notes = (ints_total_notes - ints_total_notes_min) / (ints_total_notes_max - ints_total_notes_min)\n",
    "            ints_total_pitch_bends = (ints_total_pitch_bends - ints_total_pitch_bends_min) / (ints_total_pitch_bends_max - ints_total_pitch_bends_min)\n",
    "            ints_total_control_changes = (ints_total_control_changes - ints_total_control_changes_min) / (ints_total_control_changes_max - ints_total_control_changes_min)\n",
    "\n",
    "            # Create an array of the calculated MIDI features\n",
    "            features = np.array([tempo, tempo_changes, total_velocity, piano_roll_value, ints_total_notes, ints_total_pitch_bends, ints_total_control_changes])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any exceptions that occur during feature extraction\n",
    "            print(e)\n",
    "            features = np.array([])\n",
    "\n",
    "        finally:\n",
    "            # Update the 'midi_file_features_global' column of the DataFrame with the extracted features\n",
    "            df.at[index, 'midi_file_features_global'] = features\n",
    "\n",
    "    # Return the modified DataFrame with the additional MIDI feature column\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5it [00:01,  4.41it/s]\n",
      "571it [02:54,  3.28it/s]\n",
      "31it [00:08,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = extract_and_insert_into_df_general_midi_features(test_df)\n",
    "validation_df = extract_and_insert_into_df_general_midi_features(validation_df)\n",
    "train_df = extract_and_insert_into_df_general_midi_features(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Model - \"Melody Per Song\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_to_X_y(df):\n",
    "  X_embedding, X_melody, y = [],[], []\n",
    "  word2vec_embeddings = df['word2vec_embeddings']\n",
    "  midi_file_features_global = df['midi_file_features_global']\n",
    "  for index_curr_embedding, curr_embedding in tqdm(enumerate(word2vec_embeddings)):\n",
    "    for index_vec_of_word, vec_of_word in enumerate(curr_embedding):\n",
    "      if index_vec_of_word < len(curr_embedding) - 1:\n",
    "        X_embedding.append(np.array(vec_of_word))\n",
    "        X_melody.append(np.array(midi_file_features_global.iloc[index_curr_embedding]))\n",
    "        y_temp = np.zeros(all_words_in_corpus_size)\n",
    "        lyric_token = df.iloc[index_curr_embedding]['lyrics_tokens']\n",
    "        pred_word = lyric_token[index_vec_of_word + 1]\n",
    "        y_temp[all_words_in_corpus_dict[pred_word]] = 1\n",
    "        y.append(y_temp)\n",
    "        \n",
    "  X_embeddings_arr = np.array(X_embedding)\n",
    "  X_embedding_reshape = X_embeddings_arr.reshape(X_embeddings_arr.shape[0],1, X_embeddings_arr.shape[1])\n",
    "  X_melody_arr = np.array(X_melody)\n",
    "  X_melody_reshape = X_melody_arr.reshape(X_melody_arr.shape[0],1, X_melody_arr.shape[1])\n",
    "  X = (X_embedding_reshape, X_melody_reshape)\n",
    "  Y = np.array(y)\n",
    "\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571it [00:41, 13.60it/s]\n",
      "31it [00:02, 12.69it/s]\n",
      "5it [00:00, 26.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df_X, train_df_Y = split_df_to_X_y(train_df)\n",
    "validation_df_X, validation_df_Y = split_df_to_X_y(validation_df)\n",
    "test_df_X, test_df_Y = split_df_to_X_y(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Melody_Per_Song:\n",
    "    def __init__(self, midi_features_vector_size=7, max_num_of_words=7485, dropout=0.2):\n",
    "        input_midi_features = Input(shape=(1, midi_features_vector_size), name='input_midi_features')\n",
    "        input_word_embedding = Input(shape=(1, 300), name='input_word_embedding')\n",
    "        concatenation_of_input = Concatenate(axis=2, name='concatenation_of_input')([input_word_embedding, input_midi_features])\n",
    "\n",
    "        layer = LSTM(32, return_sequences=True, dropout=dropout, name = 'first_layer_32')(concatenation_of_input)\n",
    "        layer = LSTM(64, dropout=dropout, name = 'second_layer_64')(layer)\n",
    "        layer = Dense(128, activation=\"relu\", name='third_layer_128')(layer)\n",
    "        layer = Dropout(dropout, name = 'dropout_layer')(layer)\n",
    "        output = Dense(max_num_of_words, activation=\"softmax\", name='output')(layer)\n",
    "\n",
    "        self.model = Model([input_word_embedding, input_midi_features], output, name='LSTM')\n",
    "        \n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def train_model(self, train_df_X, train_df_Y, validation_df_X, validation_df_Y, batch_size = 64, loss='categorical_crossentropy', metric_arr=['MSE', 'CosineSimilarity'], learning_rate = 0.01, optimizer = optimizers.Adam, epoch = 50):\n",
    "        \n",
    "        curr_optimizer = optimizer(learning_rate)\n",
    "        self.model.compile(loss=loss, metrics=metric_arr, optimizer= curr_optimizer)\n",
    "        \n",
    "        #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/sise/home/hersko/HW4_DL/model_per_song_tensorboard/\", histogram_freq=1)\n",
    "        earlystopping = callbacks.EarlyStopping(monitor='val_loss',mode='min', verbose = 1, patience = 15)\n",
    "        \n",
    "        # fit the model to the data\n",
    "        self.info = self.model.fit(x = train_df_X, y = train_df_Y, validation_data = [validation_df_X, validation_df_Y], batch_size = batch_size, epochs = epoch, callbacks=[earlystopping])\n",
    "\n",
    "\n",
    "    def predict_lyrics_for_single_song(self, single_song_df, num_of_words_to_predict = 50, word_to_begin=None):\n",
    "        if word_to_begin == None:\n",
    "            word_to_begin = single_song_df['lyrics_tokens'][0]\n",
    "\n",
    "        generated_song = []\n",
    "        for i in range(num_of_words_to_predict):\n",
    "            generated_song.append(word_to_begin)\n",
    "            word_embedding = w2v_model.wv[word_to_begin]\n",
    "\n",
    "            X_embedding = []\n",
    "            X_embedding.append(word_embedding)\n",
    "            X_embeddings_arr = np.array(X_embedding)\n",
    "            X_embedding_reshape = X_embeddings_arr.reshape(X_embeddings_arr.shape[0],1, X_embeddings_arr.shape[1])\n",
    "            \n",
    "            X_melody = []\n",
    "            X_melody.append(np.array(single_song_df['midi_file_features_global']))\n",
    "            X_melody_arr = np.array(X_melody)\n",
    "            X_melody_reshape = X_melody_arr.reshape(X_melody_arr.shape[0],1, X_melody_arr.shape[1])\n",
    "\n",
    "            X = (X_embedding_reshape, X_melody_reshape)\n",
    "\n",
    "            probs = self.model.predict(X)\n",
    "            list_of_word_prob = np.asarray(probs).astype('float64')\n",
    "            normalized_probs = list_of_word_prob[0] / np.sum(list_of_word_prob[0])\n",
    "            word_encoding_index = np.random.choice(len(list_of_word_prob[0]), p=normalized_probs)\n",
    "            word_to_begin = all_words_in_corpus_inverted_dict[word_encoding_index]\n",
    "\n",
    "        \n",
    "        s = single_song_df['lyrics']\n",
    "        s_list = s.split(\" & \")  # Split the string by '&'\n",
    "        list_of_lists = [lst.split() for lst in s_list]  # Split each substring into a list of words\n",
    "        len_list = [len(l) for l in list_of_lists]\n",
    "\n",
    "        counter = 0\n",
    "        internal_counter = 0\n",
    "        s=\"\"\n",
    "        for line in len_list:\n",
    "          while internal_counter!=line:\n",
    "            s+=generated_song[counter]\n",
    "            s+=\" \"\n",
    "            counter+=1\n",
    "            if counter==num_of_words_to_predict:\n",
    "              break\n",
    "            internal_counter+=1\n",
    "          print(s)\n",
    "          print(\"\\n\")\n",
    "          s=\"\"\n",
    "          internal_counter = 0\n",
    "          if counter==num_of_words_to_predict:\n",
    "            break\n",
    "        return ' '.join(generated_song)\n",
    "    \n",
    "    def show_model(self, path_name):\n",
    "        print(self.model.summary())\n",
    "        plot_model(self.model)\n",
    "        plt.show()\n",
    "        \n",
    "        # show_history(self.info.history)\n",
    "        # plot_history(self.info.history, path = path_name)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self, train_df_X, train_df_Y, test_df_X, test_df_Y):\n",
    "        train_eval = self.model.evaluate(train_df_X, train_df_Y)\n",
    "        test_eval = self.model.evaluate(test_df_X,test_df_Y)\n",
    "        print(f\"Evaluation on Train dataset - loss: {train_eval[0]}, MSE: {train_eval[1]}, cosine_similarity: {train_eval[2]}\")\n",
    "        print(f\"Evaluation on Test dataset - loss: {test_eval[0]}, MSE: {test_eval[1]}, cosine_similarity: {test_eval[2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_melody_per_song = LSTM_Model_Melody_Per_Song(max_num_of_words = all_words_in_corpus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4650/4650 [==============================] - 86s 17ms/step - loss: 6.3372 - MSE: 1.3250e-04 - cosine_similarity: 0.0944 - val_loss: 6.7836 - val_MSE: 1.3267e-04 - val_cosine_similarity: 0.0859\n",
      "Epoch 2/20\n",
      "4650/4650 [==============================] - 77s 17ms/step - loss: 6.1872 - MSE: 1.3240e-04 - cosine_similarity: 0.0967 - val_loss: 6.8962 - val_MSE: 1.3265e-04 - val_cosine_similarity: 0.0868\n",
      "Epoch 3/20\n",
      "4650/4650 [==============================] - 77s 16ms/step - loss: 6.1645 - MSE: 1.3240e-04 - cosine_similarity: 0.0969 - val_loss: 6.9681 - val_MSE: 1.3264e-04 - val_cosine_similarity: 0.0873\n",
      "Epoch 4/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1559 - MSE: 1.3239e-04 - cosine_similarity: 0.0971 - val_loss: 7.0187 - val_MSE: 1.3268e-04 - val_cosine_similarity: 0.0863\n",
      "Epoch 5/20\n",
      "4650/4650 [==============================] - 77s 17ms/step - loss: 6.1655 - MSE: 1.3241e-04 - cosine_similarity: 0.0965 - val_loss: 7.0473 - val_MSE: 1.3266e-04 - val_cosine_similarity: 0.0865\n",
      "Epoch 6/20\n",
      "4650/4650 [==============================] - 77s 17ms/step - loss: 6.1691 - MSE: 1.3241e-04 - cosine_similarity: 0.0964 - val_loss: 7.0619 - val_MSE: 1.3267e-04 - val_cosine_similarity: 0.0862\n",
      "Epoch 7/20\n",
      "4650/4650 [==============================] - 77s 17ms/step - loss: 6.1672 - MSE: 1.3241e-04 - cosine_similarity: 0.0964 - val_loss: 7.0688 - val_MSE: 1.3269e-04 - val_cosine_similarity: 0.0855\n",
      "Epoch 8/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1672 - MSE: 1.3241e-04 - cosine_similarity: 0.0965 - val_loss: 7.0621 - val_MSE: 1.3267e-04 - val_cosine_similarity: 0.0864\n",
      "Epoch 9/20\n",
      "4650/4650 [==============================] - 79s 17ms/step - loss: 6.1656 - MSE: 1.3241e-04 - cosine_similarity: 0.0965 - val_loss: 7.0626 - val_MSE: 1.3268e-04 - val_cosine_similarity: 0.0863\n",
      "Epoch 10/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1775 - MSE: 1.3242e-04 - cosine_similarity: 0.0961 - val_loss: 7.0767 - val_MSE: 1.3266e-04 - val_cosine_similarity: 0.0863\n",
      "Epoch 11/20\n",
      "4650/4650 [==============================] - 77s 17ms/step - loss: 6.1756 - MSE: 1.3242e-04 - cosine_similarity: 0.0961 - val_loss: 7.1283 - val_MSE: 1.3276e-04 - val_cosine_similarity: 0.0833\n",
      "Epoch 12/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1971 - MSE: 1.3245e-04 - cosine_similarity: 0.0951 - val_loss: 7.1278 - val_MSE: 1.3276e-04 - val_cosine_similarity: 0.0834\n",
      "Epoch 13/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1967 - MSE: 1.3245e-04 - cosine_similarity: 0.0951 - val_loss: 7.1270 - val_MSE: 1.3274e-04 - val_cosine_similarity: 0.0838\n",
      "Epoch 14/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1975 - MSE: 1.3245e-04 - cosine_similarity: 0.0951 - val_loss: 7.1239 - val_MSE: 1.3274e-04 - val_cosine_similarity: 0.0836\n",
      "Epoch 15/20\n",
      "4650/4650 [==============================] - 78s 17ms/step - loss: 6.1975 - MSE: 1.3245e-04 - cosine_similarity: 0.0951 - val_loss: 7.1299 - val_MSE: 1.3275e-04 - val_cosine_similarity: 0.0835\n",
      "Epoch 16/20\n",
      "4650/4650 [==============================] - 79s 17ms/step - loss: 6.1976 - MSE: 1.3244e-04 - cosine_similarity: 0.0951 - val_loss: 7.1299 - val_MSE: 1.3274e-04 - val_cosine_similarity: 0.0836\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_melody_per_song.train_model(train_df_X, train_df_Y, validation_df_X, validation_df_Y, batch_size = 32, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 15s 25ms/step - loss: 5.7208 - MSE: 3.8801e-04 - cosine_similarity: 0.1060\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 6.5755 - MSE: 3.8961e-04 - cosine_similarity: 0.0952\n",
      "Evaluation on Train dataset - loss: 5.720836162567139, MSE: 0.00038800502079539, cosine_similarity: 0.1059846580028534\n",
      "Evaluation on Test dataset - loss: 6.575528144836426, MSE: 0.0003896053531207144, cosine_similarity: 0.09521441906690598\n"
     ]
    }
   ],
   "source": [
    "model_melody_per_song.evaluate(train_df_X, train_df_Y, test_df_X, test_df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_embedding (InputLay  [(None, 1, 300)]    0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_midi_features (InputLaye  [(None, 1, 7)]      0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " concatenation_of_input (Concat  (None, 1, 307)      0           ['input_word_embedding[0][0]',   \n",
      " enate)                                                           'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      " first_layer_32 (LSTM)          (None, 1, 32)        43520       ['concatenation_of_input[0][0]'] \n",
      "                                                                                                  \n",
      " second_layer_64 (LSTM)         (None, 64)           24832       ['first_layer_32[0][0]']         \n",
      "                                                                                                  \n",
      " third_layer_128 (Dense)        (None, 128)          8320        ['second_layer_64[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_layer (Dropout)        (None, 128)          0           ['third_layer_128[0][0]']        \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 2543)         328047      ['dropout_layer[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 404,719\n",
      "Trainable params: 404,719\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_melody_per_song.show_model('model_melody_per_song')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Prediction on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = [\"model_melody_per_song\"]\n",
    "models = [model_melody_per_song]\n",
    "words_run = ['original_word','you', 'the','love']\n",
    "number_of_words_to_predict = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "----------model : model_melody_per_song----------song : eternal flame----------first word : close\n",
      "\n",
      "close wait time treat will I what hear \n",
      "\n",
      "\n",
      "for guitar shit wicked dont know \n",
      "\n",
      "\n",
      "you and with \n",
      "\n",
      "\n",
      "true sky my faith and \n",
      "\n",
      "\n",
      "and should be am \n",
      "\n",
      "\n",
      "past too are gentle someday a \n",
      "\n",
      "\n",
      "of on getting the on interstate finally \n",
      "\n",
      "\n",
      "on town her of you boy mind \n",
      "\n",
      "\n",
      "a too will I \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : eternal flame----------first word : you\n",
      "\n",
      "you when want they can just look yippe \n",
      "\n",
      "\n",
      "knew wear see reason you I \n",
      "\n",
      "\n",
      "more are i \n",
      "\n",
      "\n",
      "it your the my have \n",
      "\n",
      "\n",
      "what destroy come find \n",
      "\n",
      "\n",
      "through me on i dollar and \n",
      "\n",
      "\n",
      "big did is you at sail break \n",
      "\n",
      "\n",
      "out love your will she I could \n",
      "\n",
      "\n",
      "us i the the \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : eternal flame----------first word : the\n",
      "\n",
      "the what not snow are now this my \n",
      "\n",
      "\n",
      "the my need hit before needs \n",
      "\n",
      "\n",
      "then find by \n",
      "\n",
      "\n",
      "midnight i know in is \n",
      "\n",
      "\n",
      "secret cold whether my \n",
      "\n",
      "\n",
      "to ours face you not meet \n",
      "\n",
      "\n",
      "lose a the knew now they to \n",
      "\n",
      "\n",
      "it to cause harder lyin fly in \n",
      "\n",
      "\n",
      "think are losing your \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : eternal flame----------first word : love\n",
      "\n",
      "love secret when more we I find you \n",
      "\n",
      "\n",
      "cruel hurry a to so moon \n",
      "\n",
      "\n",
      "behind and you \n",
      "\n",
      "\n",
      "your the day be come \n",
      "\n",
      "\n",
      "I through find your \n",
      "\n",
      "\n",
      "will anymore bring i a and \n",
      "\n",
      "\n",
      "it hot not could will while gettin \n",
      "\n",
      "\n",
      "the we hair long need please fake \n",
      "\n",
      "\n",
      "pum brenda the a \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : eternal flame----------first word : close\n",
      "\n",
      "close me sometimes mine it like vacation thats \n",
      "\n",
      "\n",
      "why she is time song a \n",
      "\n",
      "\n",
      "girl the arms \n",
      "\n",
      "\n",
      "of the a your head \n",
      "\n",
      "\n",
      "and this out it \n",
      "\n",
      "\n",
      "all theres it me your a \n",
      "\n",
      "\n",
      "this dark slacking in lover great love \n",
      "\n",
      "\n",
      "some the loser views is that very \n",
      "\n",
      "\n",
      "your your side the \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : eternal flame----------first word : you\n",
      "\n",
      "you go follow i will tell word and \n",
      "\n",
      "\n",
      "all some christmas bomb i lose \n",
      "\n",
      "\n",
      "away much so \n",
      "\n",
      "\n",
      "they want to with i \n",
      "\n",
      "\n",
      "see can be one \n",
      "\n",
      "\n",
      "you see burning is raining moonshadow \n",
      "\n",
      "\n",
      "I will when this on come well \n",
      "\n",
      "\n",
      "a oh dont reached if my dream \n",
      "\n",
      "\n",
      "no carry me day \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : eternal flame----------first word : the\n",
      "\n",
      "the key eyes the right they and of \n",
      "\n",
      "\n",
      "it is took and say you \n",
      "\n",
      "\n",
      "get before right \n",
      "\n",
      "\n",
      "me inside hey high in \n",
      "\n",
      "\n",
      "the house lonely yeah \n",
      "\n",
      "\n",
      "yeah time why you dont and \n",
      "\n",
      "\n",
      "my name let me my hands get \n",
      "\n",
      "\n",
      "clear im beware you out we made \n",
      "\n",
      "\n",
      "my favourite where you \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : eternal flame----------first word : love\n",
      "\n",
      "love me it you there just sometimes my \n",
      "\n",
      "\n",
      "guy i have fun i are \n",
      "\n",
      "\n",
      "balloon and let \n",
      "\n",
      "\n",
      "your these of fading well \n",
      "\n",
      "\n",
      "save around then to \n",
      "\n",
      "\n",
      "need that come down stay a \n",
      "\n",
      "\n",
      "twilight one for by york your we \n",
      "\n",
      "\n",
      "bop nothing close hurry in repeat mary \n",
      "\n",
      "\n",
      "you i are to \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : honesty----------first word : if\n",
      "\n",
      "if cannot my about you \n",
      "\n",
      "\n",
      "i to im highway warm \n",
      "\n",
      "\n",
      "flesh you across way boy me are day you \n",
      "\n",
      "\n",
      "is i shall have remedy the \n",
      "\n",
      "\n",
      "hard the in i wind my experiencia \n",
      "\n",
      "\n",
      "let want if my make you star she who \n",
      "\n",
      "\n",
      "love in you touch of ever \n",
      "\n",
      "\n",
      "through cement her \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : honesty----------first word : you\n",
      "\n",
      "you be we the always \n",
      "\n",
      "\n",
      "know i em now chance \n",
      "\n",
      "\n",
      "off blue it new fool to let with me \n",
      "\n",
      "\n",
      "your have it city dont smokin \n",
      "\n",
      "\n",
      "along way the is them tonight as \n",
      "\n",
      "\n",
      "girl me found is relive cause never in native \n",
      "\n",
      "\n",
      "you to stand now just got \n",
      "\n",
      "\n",
      "have from day \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : honesty----------first word : the\n",
      "\n",
      "the hours sign head be \n",
      "\n",
      "\n",
      "anything two wanna we will \n",
      "\n",
      "\n",
      "your get was gonna in aint make and could \n",
      "\n",
      "\n",
      "cry with miss queen another could \n",
      "\n",
      "\n",
      "i high driving rendezvous subir even noche \n",
      "\n",
      "\n",
      "the you and to in too lie happy and \n",
      "\n",
      "\n",
      "it is because i the understand \n",
      "\n",
      "\n",
      "father got whom \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : honesty----------first word : love\n",
      "\n",
      "love to will hot slip \n",
      "\n",
      "\n",
      "start praise is your for \n",
      "\n",
      "\n",
      "in suppper never with dont man it bout soul \n",
      "\n",
      "\n",
      "a im got miles of ghost \n",
      "\n",
      "\n",
      "my you a am as in say \n",
      "\n",
      "\n",
      "they go and is wait know it are we \n",
      "\n",
      "\n",
      "on making are I bout find \n",
      "\n",
      "\n",
      "she you the \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : honesty----------first word : if\n",
      "\n",
      "if need if the place \n",
      "\n",
      "\n",
      "them plenty noel as a \n",
      "\n",
      "\n",
      "blood would love of so with on not a \n",
      "\n",
      "\n",
      "time ever know is a bit \n",
      "\n",
      "\n",
      "on women yeah a and needs one \n",
      "\n",
      "\n",
      "the love it dont you mirror if think a \n",
      "\n",
      "\n",
      "with us have walk the truth \n",
      "\n",
      "\n",
      "now on the \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : honesty----------first word : you\n",
      "\n",
      "you always to loved them \n",
      "\n",
      "\n",
      "stronger wishing crunch the turn \n",
      "\n",
      "\n",
      "me here change if pass we never deserve you \n",
      "\n",
      "\n",
      "aint just you cant without cry \n",
      "\n",
      "\n",
      "what is rest letting the broken pina \n",
      "\n",
      "\n",
      "inside you how quit house of your head about \n",
      "\n",
      "\n",
      "see about actors wrong every boys \n",
      "\n",
      "\n",
      "quiero if for \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : honesty----------first word : the\n",
      "\n",
      "the midnight they know i \n",
      "\n",
      "\n",
      "are the words to they \n",
      "\n",
      "\n",
      "walked was now for this to yes that me \n",
      "\n",
      "\n",
      "gonna you got funny but to \n",
      "\n",
      "\n",
      "green when theres all my the world \n",
      "\n",
      "\n",
      "want a ride ring stand look to see me \n",
      "\n",
      "\n",
      "on me you want it gotta \n",
      "\n",
      "\n",
      "you know why \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : honesty----------first word : love\n",
      "\n",
      "love no the baby and \n",
      "\n",
      "\n",
      "to face out me cryin \n",
      "\n",
      "\n",
      "will stay gimme just me your heads full walk \n",
      "\n",
      "\n",
      "just it is says my golden \n",
      "\n",
      "\n",
      "open and common voice for me up \n",
      "\n",
      "\n",
      "tell like mine you goin you love I will \n",
      "\n",
      "\n",
      "you more was the tears i \n",
      "\n",
      "\n",
      "go it is \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : lovefool----------first word : dear\n",
      "\n",
      "dear the heart course a all right \n",
      "\n",
      "\n",
      "ooh you i be die my tearing \n",
      "\n",
      "\n",
      "is quiero they music together \n",
      "\n",
      "\n",
      "coastline to to cannot is in would and \n",
      "\n",
      "\n",
      "that and la and let to \n",
      "\n",
      "\n",
      "card you de fade time their the like \n",
      "\n",
      "\n",
      "too not song love you stars \n",
      "\n",
      "\n",
      "send love two \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : lovefool----------first word : you\n",
      "\n",
      "you philosophy butterly hair dream the to \n",
      "\n",
      "\n",
      "hear star it be now it is \n",
      "\n",
      "\n",
      "we yeah every to girl \n",
      "\n",
      "\n",
      "got me year how to give on a \n",
      "\n",
      "\n",
      "little everything show midnight wildest now \n",
      "\n",
      "\n",
      "a i be you like yeah i out \n",
      "\n",
      "\n",
      "have say high is oh just \n",
      "\n",
      "\n",
      "all i want \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : lovefool----------first word : the\n",
      "\n",
      "the said mondays uptown like you off \n",
      "\n",
      "\n",
      "taking life without you baby feel go \n",
      "\n",
      "\n",
      "box ever the old chorus \n",
      "\n",
      "\n",
      "you live expensive words not could been no \n",
      "\n",
      "\n",
      "stop at it my yall life \n",
      "\n",
      "\n",
      "room heart come find and you was beautiful \n",
      "\n",
      "\n",
      "room this fucking you dreams not \n",
      "\n",
      "\n",
      "what games me \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : lovefool----------first word : love\n",
      "\n",
      "love diddley you but there with la \n",
      "\n",
      "\n",
      "baby that found to i die that \n",
      "\n",
      "\n",
      "I are loved your happens \n",
      "\n",
      "\n",
      "bout to more way my you a friendship \n",
      "\n",
      "\n",
      "and inside but gonna good what \n",
      "\n",
      "\n",
      "i con i it um again ever i \n",
      "\n",
      "\n",
      "even what before no on love \n",
      "\n",
      "\n",
      "turn my good \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : lovefool----------first word : dear\n",
      "\n",
      "dear ooh stayin you from you down \n",
      "\n",
      "\n",
      "ooh time no about i say to \n",
      "\n",
      "\n",
      "you you are i think \n",
      "\n",
      "\n",
      "will come and after outer everybody are get \n",
      "\n",
      "\n",
      "you through nowhere the natural says \n",
      "\n",
      "\n",
      "is something you til man my a obsession \n",
      "\n",
      "\n",
      "to what the evening you can \n",
      "\n",
      "\n",
      "the dimension though \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : lovefool----------first word : you\n",
      "\n",
      "you left up me they ever yes \n",
      "\n",
      "\n",
      "and we are your the nurse do \n",
      "\n",
      "\n",
      "the light do you with \n",
      "\n",
      "\n",
      "place shot are more called here i lie \n",
      "\n",
      "\n",
      "a car reading i in just \n",
      "\n",
      "\n",
      "i will play room telling into a sunshine \n",
      "\n",
      "\n",
      "right love the kill whiskey whips \n",
      "\n",
      "\n",
      "where as cause \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : lovefool----------first word : the\n",
      "\n",
      "the park the end this dont tell \n",
      "\n",
      "\n",
      "i saw more livin the and your \n",
      "\n",
      "\n",
      "your love my on that \n",
      "\n",
      "\n",
      "searching their treasure red state on why the \n",
      "\n",
      "\n",
      "good mine down the whole girl \n",
      "\n",
      "\n",
      "live your i i still time can and \n",
      "\n",
      "\n",
      "real it looking in it really \n",
      "\n",
      "\n",
      "one all to \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : lovefool----------first word : love\n",
      "\n",
      "love one but but you and one \n",
      "\n",
      "\n",
      "together your your an stormy their wants \n",
      "\n",
      "\n",
      "are free no so now \n",
      "\n",
      "\n",
      "if i are watch automatic love you i \n",
      "\n",
      "\n",
      "started why get call nothing through \n",
      "\n",
      "\n",
      "a rain but all too three with amyself \n",
      "\n",
      "\n",
      "thin sometimes one walkin you again \n",
      "\n",
      "\n",
      "it now myself \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : barbie girl----------first word : hiya\n",
      "\n",
      "hiya on \n",
      "\n",
      "\n",
      "faith just \n",
      "\n",
      "\n",
      "the maybe love of sleep alone that rockers \n",
      "\n",
      "\n",
      "it do \n",
      "\n",
      "\n",
      "oh why \n",
      "\n",
      "\n",
      "is traffic play doesnt raga to fade life \n",
      "\n",
      "\n",
      "daddy you head cannot what \n",
      "\n",
      "\n",
      "tell it you for clover the take show \n",
      "\n",
      "\n",
      "you nothing i and hot \n",
      "\n",
      "\n",
      "you made on heroes were love \n",
      "\n",
      "\n",
      "were in \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : barbie girl----------first word : you\n",
      "\n",
      "you song \n",
      "\n",
      "\n",
      "sales is \n",
      "\n",
      "\n",
      "and with singin mine forgot day she i \n",
      "\n",
      "\n",
      "boogie the \n",
      "\n",
      "\n",
      "watchin loving \n",
      "\n",
      "\n",
      "die frank and if all they start little \n",
      "\n",
      "\n",
      "already alone it chorus little \n",
      "\n",
      "\n",
      "me face know die play up back my \n",
      "\n",
      "\n",
      "see and first the when \n",
      "\n",
      "\n",
      "better will our someday love would \n",
      "\n",
      "\n",
      "have nobody \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : barbie girl----------first word : the\n",
      "\n",
      "the predict \n",
      "\n",
      "\n",
      "turn while \n",
      "\n",
      "\n",
      "but in can to love steps give i \n",
      "\n",
      "\n",
      "know i \n",
      "\n",
      "\n",
      "own love \n",
      "\n",
      "\n",
      "strange with will loser dont the you dont \n",
      "\n",
      "\n",
      "momomony farm catch can feel \n",
      "\n",
      "\n",
      "laugh someday to if want son you of \n",
      "\n",
      "\n",
      "fire are long now every \n",
      "\n",
      "\n",
      "we you no for for cries \n",
      "\n",
      "\n",
      "you want \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : barbie girl----------first word : love\n",
      "\n",
      "love he \n",
      "\n",
      "\n",
      "will you \n",
      "\n",
      "\n",
      "other me and star different bottom everybody oh \n",
      "\n",
      "\n",
      "fine should \n",
      "\n",
      "\n",
      "never care \n",
      "\n",
      "\n",
      "it dreaming baby same want be you hey \n",
      "\n",
      "\n",
      "now yeah in dirty i \n",
      "\n",
      "\n",
      "nothing love oh agree again happy night how \n",
      "\n",
      "\n",
      "waiting think beware baby all \n",
      "\n",
      "\n",
      "lies dont dont you full trouper \n",
      "\n",
      "\n",
      "for i \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : barbie girl----------first word : hiya\n",
      "\n",
      "hiya there \n",
      "\n",
      "\n",
      "again my \n",
      "\n",
      "\n",
      "love I have not it a it doesnt \n",
      "\n",
      "\n",
      "when say \n",
      "\n",
      "\n",
      "for may \n",
      "\n",
      "\n",
      "nothing to the today i wrap in life \n",
      "\n",
      "\n",
      "chaka when you when you \n",
      "\n",
      "\n",
      "cannot be get such if will love the \n",
      "\n",
      "\n",
      "rain you once i i \n",
      "\n",
      "\n",
      "was is cold say im the \n",
      "\n",
      "\n",
      "world are \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : barbie girl----------first word : you\n",
      "\n",
      "you let \n",
      "\n",
      "\n",
      "to play \n",
      "\n",
      "\n",
      "the start and monstertruck they are my chance \n",
      "\n",
      "\n",
      "yes i \n",
      "\n",
      "\n",
      "can loved \n",
      "\n",
      "\n",
      "in hand alone comes look velvet the day \n",
      "\n",
      "\n",
      "larger broke open love if \n",
      "\n",
      "\n",
      "we bop andrer with scattered dear the new \n",
      "\n",
      "\n",
      "all open you mony all \n",
      "\n",
      "\n",
      "of day time man nature the \n",
      "\n",
      "\n",
      "cruel me \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : barbie girl----------first word : the\n",
      "\n",
      "the zoot \n",
      "\n",
      "\n",
      "better you \n",
      "\n",
      "\n",
      "are gone those can see im your all \n",
      "\n",
      "\n",
      "the back \n",
      "\n",
      "\n",
      "and though \n",
      "\n",
      "\n",
      "life will love you want love my eyes \n",
      "\n",
      "\n",
      "the world has is would \n",
      "\n",
      "\n",
      "am i family it now i dont it \n",
      "\n",
      "\n",
      "is keep i just da \n",
      "\n",
      "\n",
      "da do somebody so ever be \n",
      "\n",
      "\n",
      "I will \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : barbie girl----------first word : love\n",
      "\n",
      "love girl \n",
      "\n",
      "\n",
      "you oh \n",
      "\n",
      "\n",
      "chorus you can the same will miss it \n",
      "\n",
      "\n",
      "in me \n",
      "\n",
      "\n",
      "like about \n",
      "\n",
      "\n",
      "in pain shingalingaling in we your fruitless the \n",
      "\n",
      "\n",
      "number in all is part \n",
      "\n",
      "\n",
      "going it really like me i stop this \n",
      "\n",
      "\n",
      "you still the more if \n",
      "\n",
      "\n",
      "laugh take me we would i \n",
      "\n",
      "\n",
      "found is \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : all the small things----------first word : all\n",
      "\n",
      "all me the way \n",
      "\n",
      "\n",
      "the love is she \n",
      "\n",
      "\n",
      "on a girl with \n",
      "\n",
      "\n",
      "sun tell about yeah \n",
      "\n",
      "\n",
      "mind the house \n",
      "\n",
      "\n",
      "to in faith you it \n",
      "\n",
      "\n",
      "earths no right \n",
      "\n",
      "\n",
      "mans baby it out cries a may venus \n",
      "\n",
      "\n",
      "thousand temple it she different me name \n",
      "\n",
      "\n",
      "to softly my one \n",
      "\n",
      "\n",
      "just can wonderin hope \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : all the small things----------first word : you\n",
      "\n",
      "you me call a \n",
      "\n",
      "\n",
      "all and air when \n",
      "\n",
      "\n",
      "til me it want \n",
      "\n",
      "\n",
      "white place who old \n",
      "\n",
      "\n",
      "forever school i \n",
      "\n",
      "\n",
      "is the there nothin highway \n",
      "\n",
      "\n",
      "at me you \n",
      "\n",
      "\n",
      "like of trunk you liked you my nights \n",
      "\n",
      "\n",
      "song on to wind hope the have \n",
      "\n",
      "\n",
      "the done your me \n",
      "\n",
      "\n",
      "that we it ole \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : all the small things----------first word : the\n",
      "\n",
      "the just when the \n",
      "\n",
      "\n",
      "the charlie passions to \n",
      "\n",
      "\n",
      "her dyin tragedy take \n",
      "\n",
      "\n",
      "best crews i rainy \n",
      "\n",
      "\n",
      "yeah the if \n",
      "\n",
      "\n",
      "sailors save am more and \n",
      "\n",
      "\n",
      "how new but \n",
      "\n",
      "\n",
      "see please understand I watch thats round now \n",
      "\n",
      "\n",
      "upside her like got you you is \n",
      "\n",
      "\n",
      "ghost right flesh blue \n",
      "\n",
      "\n",
      "in under at my \n",
      "\n",
      "\n",
      "----------model : model_melody_per_song----------song : all the small things----------first word : love\n",
      "\n",
      "love i the gaze \n",
      "\n",
      "\n",
      "is would yes and \n",
      "\n",
      "\n",
      "do we problem the \n",
      "\n",
      "\n",
      "know a you singing \n",
      "\n",
      "\n",
      "i we play \n",
      "\n",
      "\n",
      "on spend the a girl \n",
      "\n",
      "\n",
      "drah you dance \n",
      "\n",
      "\n",
      "eyes you saddest just could i same when \n",
      "\n",
      "\n",
      "me doesnt rhythm turn me out you \n",
      "\n",
      "\n",
      "fantasy let of could \n",
      "\n",
      "\n",
      "your too good sinners \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : all the small things----------first word : all\n",
      "\n",
      "all takes when your \n",
      "\n",
      "\n",
      "da is do for \n",
      "\n",
      "\n",
      "only always do i \n",
      "\n",
      "\n",
      "tonight be when because \n",
      "\n",
      "\n",
      "to want to \n",
      "\n",
      "\n",
      "some they cannot listen going\n",
      "\n",
      "\n",
      "freak i dont \n",
      "\n",
      "\n",
      "a long it no some these more time \n",
      "\n",
      "\n",
      "more yeah just and every ohwoho i \n",
      "\n",
      "\n",
      "could run help your \n",
      "\n",
      "\n",
      "to just know get \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : all the small things----------first word : you\n",
      "\n",
      "you cannot day going \n",
      "\n",
      "\n",
      "you punched taste without \n",
      "\n",
      "\n",
      "together let the one \n",
      "\n",
      "\n",
      "you i feel is \n",
      "\n",
      "\n",
      "much giving love \n",
      "\n",
      "\n",
      "is waits i gave said \n",
      "\n",
      "\n",
      "when it was \n",
      "\n",
      "\n",
      "give that were please my go ohh wishing \n",
      "\n",
      "\n",
      "you were theology by boardwalk the sun \n",
      "\n",
      "\n",
      "hey do you will \n",
      "\n",
      "\n",
      "gotta it to know \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : all the small things----------first word : the\n",
      "\n",
      "the lifetime win again \n",
      "\n",
      "\n",
      "you think might for \n",
      "\n",
      "\n",
      "your keep day i \n",
      "\n",
      "\n",
      "know he day oh \n",
      "\n",
      "\n",
      "for wrong she \n",
      "\n",
      "\n",
      "try me cry what is \n",
      "\n",
      "\n",
      "fucking can love \n",
      "\n",
      "\n",
      "to defend and the one i what you \n",
      "\n",
      "\n",
      "be just a bar mind the clan \n",
      "\n",
      "\n",
      "racin of for you \n",
      "\n",
      "\n",
      "are try dont i \n",
      "\n",
      "\n",
      "----------model : model_melody_per_word----------song : all the small things----------first word : love\n",
      "\n",
      "love hard you are \n",
      "\n",
      "\n",
      "could kiss i knew \n",
      "\n",
      "\n",
      "i defend and for \n",
      "\n",
      "\n",
      "reasons quite thats you \n",
      "\n",
      "\n",
      "about take night \n",
      "\n",
      "\n",
      "from got for am if \n",
      "\n",
      "\n",
      "me and they \n",
      "\n",
      "\n",
      "say around two employments was the the thousand \n",
      "\n",
      "\n",
      "right i say to be the heart \n",
      "\n",
      "\n",
      "full i can you \n",
      "\n",
      "\n",
      "wrong you make you \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, song in test_df.iterrows():\n",
    "    for index, model in enumerate(models):\n",
    "        for word in words_run:\n",
    "            if word == 'original_word':\n",
    "                word = song['lyrics_tokens'][0]\n",
    "            print(f\"----------model : {models_name[index]}----------song : {song['song']}----------first word : {word}\")\n",
    "            model.predict_lyrics_for_single_song(song, num_of_words_to_predict = number_of_words_to_predict, word_to_begin=word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Lyrics_Generator:\n",
    "    def __init__(self, lstm_model, train_lstm = False):\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss =[]\n",
    "        self.lstm_model = lstm_model\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5), metrics=['accuracy'])\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5), metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "        self.lstm_model.model.trainable = train_lstm\n",
    "        self.gan_loss =[]\n",
    "\n",
    "        self.gan = self.build_gan() \n",
    "        self.gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5))\n",
    "\n",
    "    def build_generator(self):\n",
    "        input_midi_features = Input(shape=(1, 7), name='input_midi_features')\n",
    "        input_z = Input(shape=(1, 300), name='input_z')\n",
    "        concatenation_of_input = Concatenate(axis=2, name='concatenation_of_input')([input_z, input_midi_features])\n",
    "\n",
    "        layer = Dense(128, activation=\"relu\", name = 'first_layer_128')(concatenation_of_input)\n",
    "        layer = Dense(64, activation=\"relu\", name = 'second_layer_64')(layer)\n",
    "        layer = Dense(32, activation=\"relu\", name='third_layer_32')(layer)\n",
    "        #layer = Dropout(dropout, name = 'dropout_layer')(layer)\n",
    "        output = Dense(300, name='output')(layer)\n",
    "\n",
    "        generator = Model([input_z, input_midi_features], output, name='Generator')\n",
    "        return generator\n",
    "\n",
    "    def build_discriminator(self, dropout = 0.1):\n",
    "        input_midi_features = Input(shape=(1, 7), name='input_midi_features')\n",
    "        input_real = Input(shape=(1, 300), name='input_real')\n",
    "        input_gen = Input(shape=(1, 300), name='input_gen')\n",
    "        concatenation_of_input = Concatenate(axis=2, name='concatenation_of_input')([input_gen, input_real, input_midi_features])\n",
    "\n",
    "        layer = LSTM(32, return_sequences=True, dropout=dropout, name = 'first_layer_32')(concatenation_of_input)\n",
    "        layer = LSTM(64, dropout=dropout, name = 'second_layer_64')(layer)\n",
    "        # Dense layers\n",
    "        layer = Dense(128, activation='relu', name='dense_layer128')(layer)\n",
    "        layer = Dropout(dropout, name='dropout_layer')(layer)\n",
    "        discriminator_output = Dense(1, activation='sigmoid', name='discriminator_output')(layer)\n",
    "\n",
    "        discriminator = Model([input_gen, input_real, input_midi_features], discriminator_output, name='Discriminator')\n",
    "        return discriminator\n",
    "    \n",
    "    def generator_loss(self, fake_output):\n",
    "        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        ce = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        return ce\n",
    "\n",
    "\n",
    "    def calc_gen_loss(self, predictions, batch_size, fake_output):\n",
    "        sum = 0\n",
    "        for pred in predictions:\n",
    "            pred = pred[0]\n",
    "            res = 1 - pred\n",
    "            res = np.log2(res + 1e-7)\n",
    "            if math.isinf(res):\n",
    "                res = 0\n",
    "            sum+= (-1)*res  \n",
    "        return sum/batch_size\n",
    "\n",
    "    def build_gan(self, x=300):\n",
    "\n",
    "        input_midi_features = Input(shape=(1, 7), name='input_midi_features')\n",
    "        input_z = Input(shape=(1, x), name='input_z')\n",
    "        input_real = Input(shape=(1, x), name='input_real')\n",
    "\n",
    "        output_generator = self.generator([input_z, input_midi_features])\n",
    "\n",
    "        word_embedding_tensor = tf.reshape(output_generator, (-1, 1, x), name = \"Reshape_layer_1\")\n",
    "        \n",
    "        output_lstm = self.lstm_model.model([word_embedding_tensor, input_midi_features])[:, :x] \n",
    "\n",
    "        output_lstm = tf.reshape(output_lstm, (-1, 1, x), name = \"Reshape_layer_2\")\n",
    "\n",
    "        gan_output = self.discriminator([word_embedding_tensor, input_real, input_midi_features])\n",
    "\n",
    "        gan = Model([input_z, input_real, input_midi_features], gan_output, name='GAN')\n",
    "        return gan\n",
    "\n",
    "    def create_and_train_gan(self, train_df, batch_size = 10, epochs=50, learning_rate=0.01, optimizer=optimizers.Adam):\n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "            for _, song in train_df.iterrows():\n",
    "\n",
    "                melody_emb = song['midi_file_features_global']\n",
    "                melody_emb = np.tile(melody_emb, (batch_size, 1))\n",
    "                melody_emb = np.expand_dims(melody_emb, axis=1)\n",
    "                real_lyrics_word2vec_embeddings = song['word2vec_embeddings']\n",
    "\n",
    "                idx = np.random.randint(0, len(real_lyrics_word2vec_embeddings), batch_size)\n",
    "                real_seqs = real_lyrics_word2vec_embeddings[idx]\n",
    "\n",
    "                #randomize a batch size of words (e.g. 10 words), each word is a 300 dimensional because of the word2vec\n",
    "                noise = np.random.normal(0, 1, (batch_size, 300))\n",
    "\n",
    "                noise = np.expand_dims(noise, axis=1)\n",
    "\n",
    "                # Generate a batch of new note sequences\n",
    "                output_generator = self.generator.predict_on_batch([noise, melody_emb])\n",
    "\n",
    "                # Our LSTM is recieving each time one word as input, therefore, we are running over the batchsize, and each time we are taking one output\n",
    "                # that we generated from the generator and query it to the LSTM\n",
    "                generated_seq = []\n",
    "                for i in range(batch_size):\n",
    "                    \n",
    "                    first_300 = output_generator[i, 0, :300]\n",
    "                    X_embedding = []\n",
    "                    X_embedding.append(first_300)\n",
    "                    X_embeddings_arr = np.array(X_embedding)\n",
    "                    X_embedding_reshape = X_embeddings_arr.reshape(X_embeddings_arr.shape[0],1, X_embeddings_arr.shape[1])\n",
    "                    \n",
    "                    last_7 = output_generator[i, 0, -7:]\n",
    "                    X_melody = []\n",
    "                    X_melody.append(last_7)\n",
    "                    X_melody_arr = np.array(X_melody)\n",
    "                    X_melody_reshape = X_melody_arr.reshape(X_melody_arr.shape[0],1, X_melody_arr.shape[1])\n",
    "\n",
    "                    X = (X_embedding_reshape, X_melody_reshape)\n",
    "                    \n",
    "                    probs = self.lstm_model.model.predict(X, verbose = 0)\n",
    "                    list_of_word_prob = np.asarray(probs).astype('float64')\n",
    "                    normalized_probs = list_of_word_prob[0] / np.sum(list_of_word_prob[0])\n",
    "                    output_lstm = np.random.choice(len(list_of_word_prob[0]), p=normalized_probs)\n",
    "                    output_lstm = all_words_in_corpus_inverted_dict[output_lstm]\n",
    "                    output_lstm = w2v_model.wv[output_lstm]\n",
    "\n",
    "                    generated_seq.append(output_lstm)\n",
    "                generated_seq = np.array(generated_seq)\n",
    "\n",
    "                # Train the discriminator\n",
    "                g_i = np.reshape(generated_seq, (batch_size, 1, 300))\n",
    "                x_i = np.reshape(real_seqs, (batch_size, 1, 300))\n",
    "                \n",
    "                self.discriminator.trainable = True\n",
    "                self.generator.trainable = False\n",
    "                if np.random.rand() > 0.5:\n",
    "                    # the fake (generated) is on the left\n",
    "                    real = np.ones((batch_size, 1))\n",
    "                    d_loss = self.discriminator.train_on_batch([g_i, x_i, melody_emb], real)\n",
    "                else:\n",
    "                    # the fake (generated) is on the right\n",
    "                    real = np.zeros((batch_size, 1))\n",
    "                    d_loss = self.discriminator.train_on_batch([x_i, g_i, melody_emb], real)\n",
    "\n",
    "                real = np.ones((batch_size, 1))\n",
    "                self.discriminator.trainable = False\n",
    "                self.generator.trainable = True\n",
    "                discriminator_predictions = self.discriminator.predict_on_batch([g_i, x_i, melody_emb])\n",
    "                with tf.GradientTape() as gen_tape:\n",
    "                    generated = self.generator([noise, melody_emb],training=True)\n",
    "                    gen_loss = self.generator_loss(generated)\n",
    "                    my_loss = self.calc_gen_loss(discriminator_predictions, batch_size, generated)\n",
    "                    g_loss = gen_loss * 0 + my_loss\n",
    "                    #print(f'Generator loss : {new_loss}')\n",
    "                    gradients_of_generator = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "                optimizer(learning_rate).apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                loss_gan = self.gan.train_on_batch([noise, np.reshape(real_seqs, (batch_size, 1, 300)), melody_emb], real)\n",
    "\n",
    "            self.disc_loss.append(d_loss[0])\n",
    "            self.gen_loss.append(g_loss)\n",
    "            self.gan_loss.append(loss_gan)\n",
    "\n",
    "            # Print the progress and save into   lists\n",
    "            print(\"epoch number %d , [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "    \n",
    "\n",
    "    def predict_lyrics_for_single_song(self, single_song_df, num_of_words_to_predict = 50):\n",
    "        generated_song = []\n",
    "        for i in range(num_of_words_to_predict):\n",
    "            if i == 0:\n",
    "                noise = np.random.normal(0, 1, (1, 300))\n",
    "                noise = np.expand_dims(noise, axis=1)  #Maybe change here to the last work that the GAN generated ###################################\n",
    "             \n",
    "            X_melody = []\n",
    "            X_melody.append(np.array(single_song_df['midi_file_features_global']))\n",
    "            X_melody_arr = np.array(X_melody)\n",
    "            X_melody_reshape = X_melody_arr.reshape(X_melody_arr.shape[0],1, X_melody_arr.shape[1])\n",
    "\n",
    "            generated_lyrics_from_gan = self.generator.predict([noise, X_melody_reshape])\n",
    "\n",
    "            X = (generated_lyrics_from_gan, X_melody_reshape)\n",
    "            lstm_output = self.lstm_model.model.predict(X, verbose=0)\n",
    "            list_of_word_prob = np.asarray(lstm_output).astype('float64')\n",
    "            normalized_probs = list_of_word_prob[0] / np.sum(list_of_word_prob[0])\n",
    "            word_encoding_index = np.random.choice(len(list_of_word_prob[0]), p=normalized_probs)\n",
    "            word = all_words_in_corpus_inverted_dict[word_encoding_index]\n",
    "            generated_song.append(word)\n",
    "            noise = w2v_model.wv[word]\n",
    "            noise = tf.expand_dims(noise, axis=0)\n",
    "            noise = tf.expand_dims(noise, axis=0)\n",
    "\n",
    "\n",
    "        s = single_song_df['lyrics']\n",
    "        s_list = s.split(\" & \")  # Split the string by '&'\n",
    "        list_of_lists = [lst.split() for lst in s_list]  # Split each substring into a list of words\n",
    "        len_list = [len(l) for l in list_of_lists]\n",
    "\n",
    "        counter = 0\n",
    "        internal_counter = 0\n",
    "        s=\"\"\n",
    "        for line in len_list:\n",
    "          while internal_counter!=line:\n",
    "            s+=generated_song[counter]\n",
    "            s+=\" \"\n",
    "            counter+=1\n",
    "            if counter==num_of_words_to_predict:\n",
    "              break\n",
    "            internal_counter+=1\n",
    "          print(s)\n",
    "          print(\"\\n\")\n",
    "          s=\"\"\n",
    "          internal_counter = 0\n",
    "          if counter==num_of_words_to_predict:\n",
    "            break\n",
    "        return ' '.join(generated_song)\n",
    "\n",
    "    def show_gan(self):\n",
    "        print(self.gan.summary())\n",
    "        plot_model(self.gan)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=False)\n",
    "        plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GAN with LSTM's weight FROZEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GAN_Lyrics_Generator(model_melody_per_song, train_lstm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(GAN.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(GAN.discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0 , [D loss: 0.626189] [G loss: 1.123176]\n",
      "epoch number 1 , [D loss: 0.376532] [G loss: 1.667573]\n",
      "epoch number 2 , [D loss: 1.128591] [G loss: 1.667387]\n",
      "epoch number 3 , [D loss: 0.984604] [G loss: 1.672525]\n",
      "epoch number 4 , [D loss: 0.524910] [G loss: 1.329713]\n",
      "epoch number 5 , [D loss: 0.582465] [G loss: 1.217198]\n",
      "epoch number 6 , [D loss: 0.708463] [G loss: 1.033210]\n",
      "epoch number 7 , [D loss: 0.684055] [G loss: 1.021241]\n",
      "epoch number 8 , [D loss: 0.651450] [G loss: 1.070988]\n",
      "epoch number 9 , [D loss: 0.729229] [G loss: 1.100663]\n",
      "epoch number 10 , [D loss: 0.627295] [G loss: 1.117722]\n",
      "epoch number 11 , [D loss: 0.744825] [G loss: 1.112209]\n",
      "epoch number 12 , [D loss: 0.767057] [G loss: 1.119914]\n",
      "epoch number 13 , [D loss: 0.767401] [G loss: 1.141095]\n",
      "epoch number 14 , [D loss: 0.643359] [G loss: 1.072109]\n",
      "epoch number 15 , [D loss: 0.648487] [G loss: 1.065397]\n",
      "epoch number 16 , [D loss: 0.734778] [G loss: 1.061042]\n",
      "epoch number 17 , [D loss: 0.735411] [G loss: 1.093316]\n",
      "epoch number 18 , [D loss: 0.679025] [G loss: 1.020537]\n",
      "epoch number 19 , [D loss: 0.713780] [G loss: 1.034040]\n",
      "epoch number 20 , [D loss: 0.713686] [G loss: 1.026910]\n",
      "epoch number 21 , [D loss: 0.731324] [G loss: 1.039705]\n",
      "epoch number 22 , [D loss: 0.744370] [G loss: 1.040482]\n",
      "epoch number 23 , [D loss: 0.641127] [G loss: 1.080366]\n",
      "epoch number 24 , [D loss: 0.635975] [G loss: 1.095535]\n",
      "epoch number 25 , [D loss: 0.574687] [G loss: 1.253795]\n",
      "epoch number 26 , [D loss: 0.747210] [G loss: 1.058711]\n",
      "epoch number 27 , [D loss: 0.668927] [G loss: 1.038925]\n",
      "epoch number 28 , [D loss: 0.713366] [G loss: 1.024342]\n",
      "epoch number 29 , [D loss: 0.706463] [G loss: 1.015591]\n",
      "epoch number 30 , [D loss: 0.674416] [G loss: 1.035407]\n",
      "epoch number 31 , [D loss: 0.703907] [G loss: 1.009387]\n",
      "epoch number 32 , [D loss: 0.689418] [G loss: 0.987237]\n",
      "epoch number 33 , [D loss: 0.682220] [G loss: 0.981920]\n",
      "epoch number 34 , [D loss: 0.677023] [G loss: 0.967073]\n",
      "epoch number 35 , [D loss: 0.723214] [G loss: 0.959313]\n",
      "epoch number 36 , [D loss: 0.665218] [G loss: 0.958721]\n",
      "epoch number 37 , [D loss: 0.712006] [G loss: 0.978908]\n",
      "epoch number 38 , [D loss: 0.665493] [G loss: 0.960299]\n",
      "epoch number 39 , [D loss: 0.664483] [G loss: 0.957799]\n",
      "epoch number 40 , [D loss: 0.680229] [G loss: 0.969333]\n",
      "epoch number 41 , [D loss: 0.687792] [G loss: 1.001704]\n",
      "epoch number 42 , [D loss: 0.668056] [G loss: 0.953725]\n",
      "epoch number 43 , [D loss: 0.719113] [G loss: 0.963324]\n",
      "epoch number 44 , [D loss: 0.726919] [G loss: 0.960992]\n",
      "epoch number 45 , [D loss: 0.749536] [G loss: 0.933193]\n",
      "epoch number 46 , [D loss: 0.708915] [G loss: 0.982832]\n",
      "epoch number 47 , [D loss: 0.723087] [G loss: 0.960243]\n",
      "epoch number 48 , [D loss: 0.713427] [G loss: 0.974810]\n",
      "epoch number 49 , [D loss: 0.686296] [G loss: 0.980817]\n",
      "epoch number 50 , [D loss: 0.713352] [G loss: 0.974876]\n",
      "epoch number 51 , [D loss: 0.670889] [G loss: 0.962960]\n",
      "epoch number 52 , [D loss: 0.734360] [G loss: 0.942065]\n",
      "epoch number 53 , [D loss: 0.769143] [G loss: 0.900606]\n",
      "epoch number 54 , [D loss: 0.794243] [G loss: 0.876920]\n",
      "epoch number 55 , [D loss: 0.755474] [G loss: 0.919755]\n",
      "epoch number 56 , [D loss: 0.670299] [G loss: 0.964606]\n",
      "epoch number 57 , [D loss: 0.749468] [G loss: 1.067980]\n",
      "epoch number 58 , [D loss: 0.679946] [G loss: 1.020704]\n",
      "epoch number 59 , [D loss: 0.695284] [G loss: 1.008190]\n",
      "epoch number 60 , [D loss: 0.690856] [G loss: 0.996312]\n",
      "epoch number 61 , [D loss: 0.680360] [G loss: 0.985378]\n",
      "epoch number 62 , [D loss: 0.807113] [G loss: 0.981610]\n",
      "epoch number 63 , [D loss: 0.706207] [G loss: 0.987134]\n",
      "epoch number 64 , [D loss: 0.684612] [G loss: 0.993153]\n",
      "epoch number 65 , [D loss: 0.679971] [G loss: 0.976186]\n",
      "epoch number 66 , [D loss: 0.669336] [G loss: 0.973220]\n",
      "epoch number 67 , [D loss: 0.712350] [G loss: 0.974707]\n",
      "epoch number 68 , [D loss: 0.694077] [G loss: 1.000803]\n",
      "epoch number 69 , [D loss: 0.677125] [G loss: 0.979453]\n",
      "epoch number 70 , [D loss: 0.771804] [G loss: 1.028225]\n",
      "epoch number 71 , [D loss: 0.769031] [G loss: 1.036901]\n",
      "epoch number 72 , [D loss: 0.683887] [G loss: 0.994002]\n",
      "epoch number 73 , [D loss: 0.703302] [G loss: 0.990504]\n",
      "epoch number 74 , [D loss: 0.673340] [G loss: 0.975415]\n",
      "epoch number 75 , [D loss: 0.709360] [G loss: 0.980220]\n",
      "epoch number 76 , [D loss: 0.725412] [G loss: 0.960161]\n",
      "epoch number 77 , [D loss: 0.723784] [G loss: 0.956970]\n",
      "epoch number 78 , [D loss: 0.676291] [G loss: 0.973994]\n",
      "epoch number 79 , [D loss: 0.662834] [G loss: 0.958683]\n",
      "epoch number 80 , [D loss: 1.005656] [G loss: 1.312559]\n",
      "epoch number 81 , [D loss: 0.682065] [G loss: 0.973936]\n",
      "epoch number 82 , [D loss: 0.682866] [G loss: 0.975846]\n",
      "epoch number 83 , [D loss: 0.675088] [G loss: 0.983513]\n",
      "epoch number 84 , [D loss: 0.673082] [G loss: 0.970355]\n",
      "epoch number 85 , [D loss: 0.727736] [G loss: 0.956512]\n",
      "epoch number 86 , [D loss: 0.693461] [G loss: 0.999657]\n",
      "epoch number 87 , [D loss: 0.712502] [G loss: 0.978737]\n",
      "epoch number 88 , [D loss: 0.724278] [G loss: 0.956732]\n",
      "epoch number 89 , [D loss: 0.665889] [G loss: 0.956352]\n",
      "epoch number 90 , [D loss: 0.711101] [G loss: 0.977680]\n",
      "epoch number 91 , [D loss: 0.697507] [G loss: 0.993837]\n",
      "epoch number 92 , [D loss: 0.694996] [G loss: 0.996927]\n",
      "epoch number 93 , [D loss: 0.663678] [G loss: 0.956974]\n",
      "epoch number 94 , [D loss: 0.719395] [G loss: 0.963206]\n",
      "epoch number 95 , [D loss: 0.708969] [G loss: 0.982291]\n",
      "epoch number 96 , [D loss: 0.686566] [G loss: 1.008615]\n",
      "epoch number 97 , [D loss: 0.691946] [G loss: 1.003153]\n",
      "epoch number 98 , [D loss: 0.700458] [G loss: 1.004996]\n",
      "epoch number 99 , [D loss: 0.678203] [G loss: 0.980130]\n"
     ]
    }
   ],
   "source": [
    "GAN.create_and_train_gan(train_df, batch_size = 16, epochs=100, learning_rate=0.001, optimizer=optimizers.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GAN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_z (InputLayer)           [(None, 1, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " input_midi_features (InputLaye  [(None, 1, 7)]      0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " Generator (Functional)         (None, 1, 300)       59660       ['input_z[0][0]',                \n",
      "                                                                  'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape_101 (TFOpLambda)    (None, 1, 300)       0           ['Generator[0][0]']              \n",
      "                                                                                                  \n",
      " LSTM (Functional)              (None, 2543)         404719      ['tf.reshape_101[0][0]',         \n",
      "                                                                  'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_70 (S  (None, 300)         0           ['LSTM[7][0]']                   \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.reshape_102 (TFOpLambda)    (None, 1, 300)       0           ['tf.__operators__.getitem_70[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " input_real (InputLayer)        [(None, 1, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " Discriminator (Functional)     (None, 2)            115330      ['tf.reshape_102[0][0]',         \n",
      "                                                                  'input_real[0][0]',             \n",
      "                                                                  'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 579,709\n",
      "Trainable params: 174,990\n",
      "Non-trainable params: 404,719\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "GAN.show_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # Pickle the list\n",
    "# with open('disc_loss.pickle', 'wb') as f:\n",
    "#     pickle.dump(GAN.disc_loss, f)\n",
    "\n",
    "# # Pickle the list\n",
    "# with open('gen_loss.pickle', 'wb') as f:\n",
    "#     pickle.dump(GAN.gen_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "oh coz i i another who a for \n",
      "\n",
      "\n",
      "cause says here we me okay \n",
      "\n",
      "\n",
      "tonight it for \n",
      "\n",
      "\n",
      "your im my mover only \n",
      "\n",
      "\n",
      "the are bebopalula  \n",
      "\n",
      "\n",
      "with theres the my things that \n",
      "\n",
      "\n",
      "and aint she my had to be \n",
      "\n",
      "\n",
      "when what in when runnin she someones \n",
      "\n",
      "\n",
      "her sight jokes what \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "way to you the but \n",
      "\n",
      "\n",
      "the up and if to \n",
      "\n",
      "\n",
      "cause outta ring but love me the bitch dreams \n",
      "\n",
      "\n",
      "wars might clouds away me get \n",
      "\n",
      "\n",
      "out you get on i it to \n",
      "\n",
      "\n",
      "we you cause dong you draw is you theres \n",
      "\n",
      "\n",
      "light we we verse cause them \n",
      "\n",
      "\n",
      "for we blue \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "generation simple down it a blue be \n",
      "\n",
      "\n",
      "it dr a liar say thing follow \n",
      "\n",
      "\n",
      "in out you up but \n",
      "\n",
      "\n",
      "get and wasabe smile he was on she \n",
      "\n",
      "\n",
      "my so o you needs any \n",
      "\n",
      "\n",
      "not blue your nigga me are a shining \n",
      "\n",
      "\n",
      "of away until your in me \n",
      "\n",
      "\n",
      "you i even \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "stay that \n",
      "\n",
      "\n",
      "going light \n",
      "\n",
      "\n",
      "you and slide as you but too in \n",
      "\n",
      "\n",
      "all walking \n",
      "\n",
      "\n",
      "invited we \n",
      "\n",
      "\n",
      "I weed and and if so of we \n",
      "\n",
      "\n",
      "up in hear us more \n",
      "\n",
      "\n",
      "for you da but man of the sight \n",
      "\n",
      "\n",
      "me then you inside shall \n",
      "\n",
      "\n",
      "me it i but are him \n",
      "\n",
      "\n",
      "but your \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "yall you a you \n",
      "\n",
      "\n",
      "when go look this \n",
      "\n",
      "\n",
      "so i and I \n",
      "\n",
      "\n",
      "fuckin to ask believe \n",
      "\n",
      "\n",
      "got blue this \n",
      "\n",
      "\n",
      "me me my up it \n",
      "\n",
      "\n",
      "the is me \n",
      "\n",
      "\n",
      "of record thing danced oh known your just \n",
      "\n",
      "\n",
      "space was i know im dee me \n",
      "\n",
      "\n",
      "i ho the but \n",
      "\n",
      "\n",
      "i and ace are\n"
     ]
    }
   ],
   "source": [
    "for _, song in test_df.iterrows():\n",
    "    GAN.predict_lyrics_for_single_song(song, num_of_words_to_predict = 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GAN with LSTM's weight TRAINABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GAN_Lyrics_Generator(model_melody_per_song, train_lstm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0 , [D loss: 0.800629] [G loss: 1.304221]\n",
      "epoch number 1 , [D loss: 0.660555] [G loss: 1.947493]\n",
      "epoch number 2 , [D loss: 0.207686] [G loss: 2.756545]\n",
      "epoch number 3 , [D loss: 0.543752] [G loss: 1.986199]\n",
      "epoch number 4 , [D loss: 0.412492] [G loss: 2.103874]\n",
      "epoch number 5 , [D loss: 0.513413] [G loss: 1.971640]\n",
      "epoch number 6 , [D loss: 0.288391] [G loss: 3.063819]\n",
      "epoch number 7 , [D loss: 0.291943] [G loss: 2.532311]\n",
      "epoch number 8 , [D loss: 0.675205] [G loss: 1.583015]\n",
      "epoch number 9 , [D loss: 0.492656] [G loss: 1.870920]\n",
      "epoch number 10 , [D loss: 0.868293] [G loss: 1.570154]\n",
      "epoch number 11 , [D loss: 0.640656] [G loss: 2.285330]\n",
      "epoch number 12 , [D loss: 0.537097] [G loss: 1.916484]\n",
      "epoch number 13 , [D loss: 0.308276] [G loss: 2.631794]\n",
      "epoch number 14 , [D loss: 0.455387] [G loss: 2.058688]\n",
      "epoch number 15 , [D loss: 0.360834] [G loss: 2.053675]\n",
      "epoch number 16 , [D loss: 0.351982] [G loss: 2.341696]\n",
      "epoch number 17 , [D loss: 0.540428] [G loss: 1.603070]\n",
      "epoch number 18 , [D loss: 0.707166] [G loss: 1.770248]\n",
      "epoch number 19 , [D loss: 0.353437] [G loss: 2.305405]\n",
      "epoch number 20 , [D loss: 0.571832] [G loss: 1.515142]\n",
      "epoch number 21 , [D loss: 0.465448] [G loss: 1.679696]\n",
      "epoch number 22 , [D loss: 0.771160] [G loss: 1.788211]\n",
      "epoch number 23 , [D loss: 0.436032] [G loss: 1.990343]\n",
      "epoch number 24 , [D loss: 0.361143] [G loss: 2.733841]\n",
      "epoch number 25 , [D loss: 0.463926] [G loss: 2.396022]\n",
      "epoch number 26 , [D loss: 0.656591] [G loss: 1.991663]\n",
      "epoch number 27 , [D loss: 0.489991] [G loss: 2.040972]\n",
      "epoch number 28 , [D loss: 0.258972] [G loss: 1.862765]\n",
      "epoch number 29 , [D loss: 0.617403] [G loss: 2.177830]\n",
      "epoch number 30 , [D loss: 0.536969] [G loss: 1.784962]\n",
      "epoch number 31 , [D loss: 0.703099] [G loss: 2.250633]\n",
      "epoch number 32 , [D loss: 0.500250] [G loss: 2.011907]\n",
      "epoch number 33 , [D loss: 0.489514] [G loss: 1.775873]\n",
      "epoch number 34 , [D loss: 0.555884] [G loss: 1.684743]\n",
      "epoch number 35 , [D loss: 0.695199] [G loss: 2.313324]\n",
      "epoch number 36 , [D loss: 0.305304] [G loss: 3.848086]\n",
      "epoch number 37 , [D loss: 0.311390] [G loss: 2.740151]\n",
      "epoch number 38 , [D loss: 0.403272] [G loss: 2.037405]\n",
      "epoch number 39 , [D loss: 0.477638] [G loss: 1.977814]\n",
      "epoch number 40 , [D loss: 0.554084] [G loss: 1.740237]\n",
      "epoch number 41 , [D loss: 0.415203] [G loss: 2.337251]\n",
      "epoch number 42 , [D loss: 0.931269] [G loss: 2.763036]\n",
      "epoch number 43 , [D loss: 0.389179] [G loss: 2.237982]\n",
      "epoch number 44 , [D loss: 0.338656] [G loss: 1.834918]\n",
      "epoch number 45 , [D loss: 0.617768] [G loss: 1.772984]\n",
      "epoch number 46 , [D loss: 0.365525] [G loss: 2.532339]\n",
      "epoch number 47 , [D loss: 0.309636] [G loss: 1.727626]\n",
      "epoch number 48 , [D loss: 0.554145] [G loss: 1.709311]\n",
      "epoch number 49 , [D loss: 0.415878] [G loss: 2.037837]\n",
      "epoch number 50 , [D loss: 0.856728] [G loss: 1.734009]\n",
      "epoch number 51 , [D loss: 0.414303] [G loss: 2.375921]\n",
      "epoch number 52 , [D loss: 0.584078] [G loss: 2.655629]\n",
      "epoch number 53 , [D loss: 0.393318] [G loss: 2.302935]\n",
      "epoch number 54 , [D loss: 0.124920] [G loss: 3.579951]\n",
      "epoch number 55 , [D loss: 0.463033] [G loss: 2.303895]\n",
      "epoch number 56 , [D loss: 0.302245] [G loss: 2.793819]\n",
      "epoch number 57 , [D loss: 0.417408] [G loss: 2.341665]\n",
      "epoch number 58 , [D loss: 0.215484] [G loss: 2.733406]\n",
      "epoch number 59 , [D loss: 0.409171] [G loss: 2.079149]\n",
      "epoch number 60 , [D loss: 0.631552] [G loss: 1.321753]\n",
      "epoch number 61 , [D loss: 0.328596] [G loss: 2.818653]\n",
      "epoch number 62 , [D loss: 0.680345] [G loss: 0.923342]\n",
      "epoch number 63 , [D loss: 0.667920] [G loss: 1.500020]\n",
      "epoch number 64 , [D loss: 0.351585] [G loss: 2.298965]\n",
      "epoch number 65 , [D loss: 0.467052] [G loss: 2.181714]\n",
      "epoch number 66 , [D loss: 0.245121] [G loss: 1.861537]\n",
      "epoch number 67 , [D loss: 0.456896] [G loss: 0.994563]\n",
      "epoch number 68 , [D loss: 0.661488] [G loss: 1.667876]\n",
      "epoch number 69 , [D loss: 0.306661] [G loss: 2.273578]\n",
      "epoch number 70 , [D loss: 0.853695] [G loss: 1.607913]\n",
      "epoch number 71 , [D loss: 0.323577] [G loss: 1.976646]\n",
      "epoch number 72 , [D loss: 0.543602] [G loss: 3.847704]\n",
      "epoch number 73 , [D loss: 0.268559] [G loss: 2.499964]\n",
      "epoch number 74 , [D loss: 0.341179] [G loss: 2.313187]\n",
      "epoch number 75 , [D loss: 0.351256] [G loss: 2.439553]\n",
      "epoch number 76 , [D loss: 0.608281] [G loss: 1.439410]\n",
      "epoch number 77 , [D loss: 0.687798] [G loss: 2.045931]\n",
      "epoch number 78 , [D loss: 0.210176] [G loss: 2.652552]\n",
      "epoch number 79 , [D loss: 0.389089] [G loss: 2.267765]\n",
      "epoch number 80 , [D loss: 0.436989] [G loss: 2.161503]\n",
      "epoch number 81 , [D loss: 0.433257] [G loss: 1.952965]\n",
      "epoch number 82 , [D loss: 0.313105] [G loss: 2.542083]\n",
      "epoch number 83 , [D loss: 0.616490] [G loss: 1.850443]\n",
      "epoch number 84 , [D loss: 0.665700] [G loss: 2.393838]\n",
      "epoch number 85 , [D loss: 0.426231] [G loss: 1.739288]\n",
      "epoch number 86 , [D loss: 0.290067] [G loss: 1.742555]\n",
      "epoch number 87 , [D loss: 0.373457] [G loss: 1.543372]\n",
      "epoch number 88 , [D loss: 0.487524] [G loss: 2.086589]\n",
      "epoch number 89 , [D loss: 0.205097] [G loss: 3.383565]\n",
      "epoch number 90 , [D loss: 0.751225] [G loss: 1.766310]\n",
      "epoch number 91 , [D loss: 0.430808] [G loss: 2.006214]\n",
      "epoch number 92 , [D loss: 0.454792] [G loss: 1.844488]\n",
      "epoch number 93 , [D loss: 0.341904] [G loss: 2.295425]\n",
      "epoch number 94 , [D loss: 0.400360] [G loss: 1.972905]\n",
      "epoch number 95 , [D loss: 0.280910] [G loss: 2.294569]\n",
      "epoch number 96 , [D loss: 0.668548] [G loss: 1.908702]\n",
      "epoch number 97 , [D loss: 0.601030] [G loss: 1.568486]\n",
      "epoch number 98 , [D loss: 0.433183] [G loss: 1.810318]\n",
      "epoch number 99 , [D loss: 0.640315] [G loss: 1.660606]\n"
     ]
    }
   ],
   "source": [
    "GAN.create_and_train_gan(train_df, batch_size = 8, epochs=100, learning_rate=0.001, optimizer=optimizers.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GAN\"\n",
      "__________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_z (InputLayer)           [(None, 1, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " input_midi_features (InputLaye  [(None, 1, 7)]      0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " Generator (Functional)         (None, 1, 300)       59660       ['input_z[0][0]',                \n",
      "                                                                  'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1, 300)       0           ['Generator[0][0]']              \n",
      "                                                                                                  \n",
      " LSTM (Functional)              (None, 2543)         404719      ['tf.reshape[0][0]',             \n",
      "                                                                  'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      " tf._operators_.getitem (Slic  (None, 300)         0           ['LSTM[0][0]']                   \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 1, 300)       0           ['tf._operators_.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " input_real (InputLayer)        [(None, 1, 300)]     0           []                               \n",
      "                                                                                                  \n",
      " Discriminator (Functional)     (None, 2)            115330      ['tf.reshape_1[0][0]',           \n",
      "                                                                  'input_real[0][0]',             \n",
      "                                                                  'input_midi_features[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 579,709\n",
      "Trainable params: 579,709\n",
      "Non-trainable params: 0\n",
      "__________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "GAN.show_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "is with gotta so simon if a minute \n",
      "\n",
      "\n",
      "we she to we dont it \n",
      "\n",
      "\n",
      "when that with \n",
      "\n",
      "\n",
      "am i a more thats \n",
      "\n",
      "\n",
      "be cause and away \n",
      "\n",
      "\n",
      "then there were than up are \n",
      "\n",
      "\n",
      "like no better from he dressed a \n",
      "\n",
      "\n",
      "york another another my cat not okay \n",
      "\n",
      "\n",
      "thats whats the slip \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "im help a it on \n",
      "\n",
      "\n",
      "train that whats was for \n",
      "\n",
      "\n",
      "what baby bottle other a im the on for \n",
      "\n",
      "\n",
      "i so on the and we \n",
      "\n",
      "\n",
      "right stan no to be race oh \n",
      "\n",
      "\n",
      "a a little I dreams special about a better \n",
      "\n",
      "\n",
      "why i the when me to \n",
      "\n",
      "\n",
      "give thats on \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "another it red t you dont see \n",
      "\n",
      "\n",
      "me is with the up with cryin \n",
      "\n",
      "\n",
      "i everybody you that to \n",
      "\n",
      "\n",
      "news are york a some i the get \n",
      "\n",
      "\n",
      "i woohoo in around it i \n",
      "\n",
      "\n",
      "dream thing friend since days aboard with your \n",
      "\n",
      "\n",
      "old dream so who be the \n",
      "\n",
      "\n",
      "the i holdin \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "like i \n",
      "\n",
      "\n",
      "a daa \n",
      "\n",
      "\n",
      "be how and all no i you to \n",
      "\n",
      "\n",
      "inside a \n",
      "\n",
      "\n",
      "i why \n",
      "\n",
      "\n",
      "was fuck for is get are very as \n",
      "\n",
      "\n",
      "and it im we be \n",
      "\n",
      "\n",
      "you i if to when and up soul \n",
      "\n",
      "\n",
      "to my ooh to go \n",
      "\n",
      "\n",
      "you them it my it ring \n",
      "\n",
      "\n",
      "another when \n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "that weaver to round \n",
      "\n",
      "\n",
      "when yo i will \n",
      "\n",
      "\n",
      "in she can no \n",
      "\n",
      "\n",
      "of thing first is \n",
      "\n",
      "\n",
      "karma you be \n",
      "\n",
      "\n",
      "at to sure a not \n",
      "\n",
      "\n",
      "thats start very \n",
      "\n",
      "\n",
      "can is to simple if waits than wonderland \n",
      "\n",
      "\n",
      "now soul i know these cause of \n",
      "\n",
      "\n",
      "she will  your \n",
      "\n",
      "\n",
      "make that but were\n"
     ]
    }
   ],
   "source": [
    "for _, song in test_df.iterrows():\n",
    "    GAN.predict_lyrics_for_single_song(song, num_of_words_to_predict = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
